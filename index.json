{
  "advanced/dependency-injection.html": {
    "href": "advanced/dependency-injection.html",
    "title": "Dependency injection | Polly",
    "keywords": "Dependency injection Starting with version 8, Polly provides features that make the integration of Polly with the .NET IServiceCollection Dependency Injection (DI) container more streamlined. This is a thin layer atop the resilience pipeline registry which manages resilience pipelines. Usage To use the DI functionality, add the Polly.Extensions package to your project: dotnet add package Polly.Extensions Afterwards, you can use the AddResiliencePipeline(...) extension method to set up your pipeline: var services = new ServiceCollection(); // Define a resilience pipeline services.AddResiliencePipeline(\"my-key\", builder => { // Add strategies to your pipeline here, timeout for example builder.AddTimeout(TimeSpan.FromSeconds(10)); }); // You can also access IServiceProvider by using the alternate overload services.AddResiliencePipeline(\"my-key\", (builder, context) => { // Resolve any service from DI var loggerFactory = context.ServiceProvider.GetRequiredService<ILoggerFactory>(); // Add strategies to your pipeline here builder.AddTimeout(TimeSpan.FromSeconds(10)); }); // Resolve the resilience pipeline ServiceProvider serviceProvider = services.BuildServiceProvider(); ResiliencePipelineProvider<string> pipelineProvider = serviceProvider.GetRequiredService<ResiliencePipelineProvider<string>>(); ResiliencePipeline pipeline = pipelineProvider.GetPipeline(\"my-key\"); // Use it await pipeline.ExecuteAsync( static async cancellation => await Task.Delay(100, cancellation)); The AddResiliencePipeline extension method also registers the following services into the DI container: ResiliencePipelineRegistry<string>: Allows adding and retrieving resilience pipelines. ResiliencePipelineProvider<string>: Allows retrieving resilience pipelines. IOptions<ResiliencePipelineRegistryOptions<string>>: Options for ResiliencePipelineRegistry<string>. Note The generic `string`` is inferred since the pipeline was defined using the \"my-key\" value. If you only need the registry without defining a pipeline, use the AddResiliencePipelineRegistry(...) method. Generic resilience pipelines You can also define generic resilience pipelines (ResiliencePipeline<T>), as demonstrated below: var services = new ServiceCollection(); // Define a generic resilience pipeline // First parameter is the type of key, second one is the type of the results the generic pipeline works with services.AddResiliencePipeline<string, HttpResponseMessage>(\"my-pipeline\", builder => { builder.AddRetry(new() { MaxRetryAttempts = 2, ShouldHandle = new PredicateBuilder<HttpResponseMessage>() .Handle<HttpRequestException>() .Handle<TimeoutRejectedException>() .HandleResult(response => response.StatusCode == System.Net.HttpStatusCode.InternalServerError) }) .AddTimeout(TimeSpan.FromSeconds(2)); }); // Resolve the resilience pipeline ServiceProvider serviceProvider = services.BuildServiceProvider(); ResiliencePipelineProvider<string> pipelineProvider = serviceProvider.GetRequiredService<ResiliencePipelineProvider<string>>(); ResiliencePipeline<HttpResponseMessage> pipeline = pipelineProvider.GetPipeline<HttpResponseMessage>(\"my-key\"); // Use it await pipeline.ExecuteAsync( async cancellation => await client.GetAsync(endpoint, cancellation), cancellationToken); Dynamic reloads Dynamic reloading is a feature of the pipeline registry that is also surfaced when using the AddResiliencePipeline(...) extension method. Use an overload that provides access to AddResiliencePipelineContext: services .Configure<RetryStrategyOptions>(\"my-retry-options\", configurationSection) // Configure the options .AddResiliencePipeline(\"my-pipeline\", (builder, context) => { // Enable the reloads whenever the named options change context.EnableReloads<RetryStrategyOptions>(\"my-retry-options\"); // Utility method to retrieve the named options var retryOptions = context.GetOptions<RetryStrategyOptions>(\"my-retry-options\"); // Add retries using the resolved options builder.AddRetry(retryOptions); }); EnableReloads<T>(...) activates the dynamic reloading of my-pipeline. RetryStrategyOptions are fetched using context.GetOptions(...) utility method. A retry strategy is added. During a reload: The callback re-executes. The previous pipeline is discarded. If an error occurs during reloading, the old pipeline remains, and dynamic reloading stops. Resource disposal Like dynamic reloading, the pipeline registry's resource disposal feature lets you register callbacks. These callbacks run when the pipeline is discarded, reloaded, or the registry is disposed at application shutdown. See the example below: services.AddResiliencePipeline(\"my-pipeline\", (builder, context) => { // Create disposable resource var limiter = new ConcurrencyLimiter(new ConcurrencyLimiterOptions { PermitLimit = 100, QueueLimit = 100 }); // Use it builder.AddRateLimiter(limiter); // Dispose the resource created in the callback when the pipeline is discarded context.OnPipelineDisposed(() => limiter.Dispose()); }); This feature ensures that resources are properly disposed when a pipeline reloads, discarding the old version. Complex pipeline keys The AddResiliencePipeline(...) method supports complex pipeline keys. This capability allows you to define the structure of your pipeline and dynamically resolve and cache multiple instances of the pipeline with different keys. Start by defining your complex key: public record struct MyPipelineKey(string PipelineName, string InstanceName) { } Next, register your pipeline: services.AddResiliencePipeline(new MyPipelineKey(\"my-pipeline\", string.Empty), builder => { // Circuit breaker is a stateful strategy. To isolate the builder across different pipelines, // we must use multiple instances. builder.AddCircuitBreaker(new CircuitBreakerStrategyOptions()); }); The \"my-pipeline\" pipeline is now registered. Note that the InstanceName is an empty string. While we're registering the builder action for a specific pipeline, the InstanceName parameter isn't used during the pipeline's registration. Some further modifications are required for this to function. Introduce the PipelineNameComparer: public sealed class PipelineNameComparer : IEqualityComparer<MyPipelineKey> { public bool Equals(MyPipelineKey x, MyPipelineKey y) => x.PipelineName == y.PipelineName; public int GetHashCode(MyPipelineKey obj) => (obj.PipelineName, obj.InstanceName).GetHashCode(); } Then, configure the registry behavior: services .AddResiliencePipelineRegistry<MyPipelineKey>(options => { options.BuilderComparer = new PipelineNameComparer(); options.InstanceNameFormatter = key => key.InstanceName; options.BuilderNameFormatter = key => key.PipelineName; }); Let's summarize our actions: We assigned the PipelineNameComparer instance to the BuilderComparer property. This action changes the default registry behavior, ensuring that only the PipelineName is used to find the associated builder. We used the InstanceNameFormatter delegate to represent the MyPipelineKey as an instance name for telemetry purposes, keeping the instance name as it is. Likewise, the BuilderNameFormatter delegate represents the MyPipelineKey as a builder name in telemetry. Finally, use the ResiliencePipelineProvider<MyPipelineKey> to dynamically create and cache multiple instances of the same pipeline: ResiliencePipelineProvider<MyPipelineKey> pipelineProvider = serviceProvider.GetRequiredService<ResiliencePipelineProvider<MyPipelineKey>>(); // The registry dynamically creates and caches instance-A using the associated builder action ResiliencePipeline instanceA = pipelineProvider.GetPipeline(new MyPipelineKey(\"my-pipeline\", \"instance-A\")); // The registry creates and caches instance-B ResiliencePipeline instanceB = pipelineProvider.GetPipeline(new MyPipelineKey(\"my-pipeline\", \"instance-B\")); Patterns and anti-patterns Over the years, many developers have used Polly in various ways. Some of these recurring patterns may not be ideal. This section highlights the recommended practices and those to avoid. 1 - Accessing the IServiceCollection instead of IServiceProvider ❌ DON'T Capture IServiceCollection inside AddResiliencePipeline(): var services = new ServiceCollection(); services.AddResiliencePipeline(\"myFavoriteStrategy\", builder => { builder.AddRetry(new() { OnRetry = args => { var serviceProvider = services.BuildServiceProvider(); var logger = serviceProvider.GetService<ILogger>(); // ... return default; } }); }); Reasoning: This approach builds a new ServiceProvider before each retry attempt unnecessarily. ✅ DO Use another overload of AddResiliencePipeline() which allows access to IServiceProvider: var services = new ServiceCollection(); services.AddResiliencePipeline(\"myFavoriteStrategy\", static (builder, context) => { builder.AddRetry(new() { OnRetry = args => { var logger = context.ServiceProvider.GetService<ILogger>(); // ... return default; } }); }); Reasoning: This approach uses the already built ServiceProvider and uses the same instance before every retry attempts."
  },
  "advanced/performance.html": {
    "href": "advanced/performance.html",
    "title": "Performance | Polly",
    "keywords": "Performance Polly is fast and avoids allocations wherever possible. We use a comprehensive set of performance benchmarks to monitor Polly's performance. Here's an example of results from an advanced pipeline composed of the following strategies: Timeout (outer) Rate limiter Retry Circuit breaker Timeout (inner) Method Mean Error StdDev Ratio RatioSD Gen0 Allocated Alloc Ratio Execute policy v7 2.277 μs 0.0133 μs 0.0191 μs 1.00 0.00 0.1106 2824 B 1.00 Execute pipeline v8 2.089 μs 0.0105 μs 0.0157 μs 0.92 0.01 - 40 B 0.01 Compared to older versions, Polly v8 is both faster and more memory efficient. Performance tips If you're aiming for the best performance with Polly, consider these tips: Use static lambdas Lambdas capturing variables from their outer scope will allocate on every execution. Polly provides tools to avoid this overhead, as shown in the example below: // This call allocates for each invocation since the \"userId\" variable is captured from the outer scope. await resiliencePipeline.ExecuteAsync( cancellationToken => GetMemberAsync(userId, cancellationToken), cancellationToken); // This approach uses a static lambda, avoiding allocations. // The \"userId\" is stored as state, and the lambda consumes it. await resiliencePipeline.ExecuteAsync( static (state, cancellationToken) => GetMemberAsync(state, cancellationToken), userId, cancellationToken); Use switch expressions for predicates The PredicateBuilder maintains a list of all registered predicates. To determine whether the results should be processed, it iterates through this list. Using switch expressions can help you bypass this overhead. // Here, PredicateBuilder is used to configure which exceptions the retry strategy should handle. new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = new PredicateBuilder() .Handle<SomeExceptionType>() .Handle<InvalidOperationException>() .Handle<HttpRequestException>() }) .Build(); // For optimal performance, it's recommended to use switch expressions instead of PredicateBuilder. new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = args => args.Outcome.Exception switch { SomeExceptionType => PredicateResult.True(), InvalidOperationException => PredicateResult.True(), HttpRequestException => PredicateResult.True(), _ => PredicateResult.False() } }) .Build(); Execute callbacks without throwing exceptions Polly provides the ExecuteOutcomeAsync API, returning results as Outcome<T>. The Outcome<T> might contain an exception instance, which you can check without it being thrown. This is beneficial when employing exception-heavy resilience strategies, like circuit breakers. // Execute GetMemberAsync and handle exceptions externally. try { await pipeline.ExecuteAsync(cancellationToken => GetMemberAsync(id, cancellationToken), cancellationToken); } catch (Exception e) { // Log the exception here. logger.LogWarning(e, \"Failed to get member with id '{id}'.\", id); } // The example above can be restructured as: // Acquire a context from the pool ResilienceContext context = ResilienceContextPool.Shared.Get(cancellationToken); // Instead of wrapping pipeline execution with try-catch, use ExecuteOutcomeAsync(...). // Certain strategies are optimized for this method, returning an exception instance without actually throwing it. Outcome<Member> outcome = await pipeline.ExecuteOutcomeAsync( static async (context, state) => { // The callback for ExecuteOutcomeAsync must return an Outcome<T> instance. Hence, some wrapping is needed. try { return Outcome.FromResult(await GetMemberAsync(state, context.CancellationToken)); } catch (Exception e) { return Outcome.FromException<Member>(e); } }, context, id); // Handle exceptions using the Outcome<T> instance instead of try-catch. if (outcome.Exception is not null) { logger.LogWarning(outcome.Exception, \"Failed to get member with id '{id}'.\", id); } // Release the context back to the pool ResilienceContextPool.Shared.Return(context); Reuse resilience pipeline instances Creating a resilience pipeline can be resource-intensive, so it's advisable not to discard the instance after each use. Instead, you can either cache the resilience pipeline or use the GetOrAddPipeline(...) method from ResiliencePipelineRegistry<T> to cache the pipeline dynamically: public class MyApi { private readonly ResiliencePipelineRegistry<string> _registry; // Share a single instance of the registry throughout your application. public MyApi(ResiliencePipelineRegistry<string> registry) { _registry = registry; } public async Task UpdateData(CancellationToken cancellationToken) { // Get or create the pipeline, and then cache it for subsequent use. // Choose a sufficiently unique key to prevent collisions. var pipeline = _registry.GetOrAddPipeline(\"my-app.my-api\", builder => { builder.AddRetry(new() { ShouldHandle = new PredicateBuilder() .Handle<InvalidOperationException>() .Handle<HttpRequestException>() }); }); await pipeline.ExecuteAsync(async token => { // Place your logic here }, cancellationToken); } } Note You can also define your pipeline on startup using dependency injection and then use ResiliencePipelineProvider<T> to retrieve the instance."
  },
  "advanced/resilience-context.html": {
    "href": "advanced/resilience-context.html",
    "title": "Resilience context | Polly",
    "keywords": "Resilience context The ResilienceContext class in Polly provides an execution-scoped instance that accompanies each execution through a Polly resilience strategy. This class serves to share context and facilitate information exchange between the pre-execution, mid-execution, and post-execution phases. The resilience context exposes several properties: OperationKey: A user-defined identifier for the operation. CancellationToken: The cancellation token linked to the operation. Properties: An instance of ResilienceProperties for attaching custom data to the context. ContinueOnCapturedContext: Specifies whether the asynchronous execution should continue on the captured context. Usage Below is an example demonstrating how to work with ResilienceContext: // Retrieve a context with a cancellation token ResilienceContext context = ResilienceContextPool.Shared.Get(cancellationToken); // Attach custom data to the context context.Properties.Set(MyResilienceKeys.Key1, \"my-data\"); context.Properties.Set(MyResilienceKeys.Key2, 123); // Utilize the context in a resilience pipeline ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddRetry(new() { OnRetry = static args => { // Retrieve custom data from the context, if available if (args.Context.Properties.TryGetValue(MyResilienceKeys.Key1, out var data)) { Console.WriteLine(\"OnRetry, Custom Data: {0}\", data); } return default; } }) .Build(); // Execute the resilience pipeline asynchronously await pipeline.ExecuteAsync( static async context => { // Insert your execution logic here }, context); // Return the context to the pool ResilienceContextPool.Shared.Return(context); Where ResilienceKeys is defined as: public static class MyResilienceKeys { public static readonly ResiliencePropertyKey<string> Key1 = new(\"my-key-1\"); public static readonly ResiliencePropertyKey<int> Key2 = new(\"my-key-2\"); } Note We recommend defining a static class to hold the resilience property keys used in your project. This approach makes these keys easier to discover and maintain. For simpler scenarios, you can directly use the creation of ResiliencePropertyKey<string> since it's a cheap, struct-based API. Resilient context pooling The ResilienceContext object is resource-intensive to create, and recreating it for each execution would negatively impact performance. To address this issue, Polly provides a ResilienceContextPool. This pool allows you to obtain and reuse ResilienceContext instances. Once you've finished using a context instance, you can return it to the pool. This action will reset the context to its initial state, making it available for reuse. The ResilienceContextPool offers several Get methods. These methods not only allow you to retrieve a ResilienceContext instance, but also enable you to initialize some of its properties at the time of retrieval. // Retrieve a context with a cancellation token ResilienceContext context = ResilienceContextPool.Shared.Get(cancellationToken); try { // Retrieve a context with a specific operation key context = ResilienceContextPool.Shared.Get(\"my-operation-key\", cancellationToken); // Retrieve a context with multiple properties context = ResilienceContextPool.Shared.Get( operationKey: \"my-operation-key\", continueOnCapturedContext: true, cancellationToken: cancellationToken); // Use the pool here } finally { // Returning the context back to the pool is recommended, but not required as it reduces the allocations. // It is also OK to not return the context in case of exceptions, if you want to avoid try-catch blocks. ResilienceContextPool.Shared.Return(context); } Note The OperationKey values are reported in telemetry. Beware of using very large or unbounded combinations for the operation key. See best practices for more details."
  },
  "advanced/simmy.html": {
    "href": "advanced/simmy.html",
    "title": "Chaos engineering with Simmy | Polly",
    "keywords": "Chaos engineering with Simmy Simmy is a major new companion project adding a chaos-engineering and fault-injection dimension to Polly, through the provision of policies to selectively inject faults or latency. Head over to the Simmy repository to find out more."
  },
  "advanced/telemetry.html": {
    "href": "advanced/telemetry.html",
    "title": "Telemetry | Polly",
    "keywords": "Telemetry Starting with version 8, Polly provides telemetry for all built-in resilience strategies. Usage To enable telemetry in Polly, add the Polly.Extensions package to your project: dotnet add package Polly.Extensions Afterwards, you can use the ConfigureTelemetry(...) extension method on the ResiliencePipelineBuilder: var telemetryOptions = new TelemetryOptions { // Configure logging LoggerFactory = LoggerFactory.Create(builder => builder.AddConsole()) }; // Configure enrichers telemetryOptions.MeteringEnrichers.Add(new MyMeteringEnricher()); // Configure telemetry listeners telemetryOptions.TelemetryListeners.Add(new MyTelemetryListener()); var builder = new ResiliencePipelineBuilder() .AddTimeout(TimeSpan.FromSeconds(1)) .ConfigureTelemetry(telemetryOptions) // This method enables telemetry in the builder .Build(); The MyTelemetryListener and MyMeteringEnricher is implemented as: internal class MyTelemetryListener : TelemetryListener { public override void Write<TResult, TArgs>(in TelemetryEventArguments<TResult, TArgs> args) { Console.WriteLine($\"Telemetry event occurred: {args.Event.EventName}\"); } } internal class MyMeteringEnricher : MeteringEnricher { public override void Enrich<TResult, TArgs>(in EnrichmentContext<TResult, TArgs> context) { context.Tags.Add(new(\"my-custom-tag\", \"custom-value\")); } } Alternatively, you can use the AddResiliencePipeline(...) extension method which automatically enables telemetry for defined pipeline: var serviceCollection = new ServiceCollection() .AddLogging(builder => builder.AddConsole()) .AddResiliencePipeline(\"my-strategy\", builder => builder.AddTimeout(TimeSpan.FromSeconds(1))) .Configure<TelemetryOptions>(options => { // Configure enrichers options.MeteringEnrichers.Add(new MyMeteringEnricher()); // Configure telemetry listeners options.TelemetryListeners.Add(new MyTelemetryListener()); }); Metrics The metrics are emitted under the Polly meter name. The subsequent sections provide insights into the metrics produced by Polly. Please note that any custom enriched tags are not depicted in the following tables. Every telemetry event has the following tags: pipeline.name: Optional, comes from ResiliencePipelineBuilder.Name. pipeline.instance: Optional, comes from ResiliencePipelineBuilder.InstanceName. strategy.name: Optional, comes from RetryStrategyOptions.Name. operation.key: Optional, comes from ResilienceContext.OperationKey. The sample below demonstrates how to assign these tags: var builder = new ResiliencePipelineBuilder(); builder.Name = \"my-name\"; builder.Name = \"my-instance-name\"; builder.AddRetry(new RetryStrategyOptions { // The default value is \"Retry\" Name = \"my-retry-name\" }); ResiliencePipeline pipeline = builder.Build(); // Create resilience context with operation key ResilienceContext resilienceContext = ResilienceContextPool.Shared.Get(\"my-operation-key\"); // Execute the pipeline with the context pipeline.Execute( context => { // Your code comes here }, resilienceContext); Note Beware of using very large or unbounded combinations of tag values for the tags above. See best practices for more details. These values are subsequently reflected in the following metering instruments exposed by Polly: Instrument: resilience.polly.strategy.events Type: Counter Numerical type of measurement: int Description: Emitted upon the occurrence of a resilience event. Tags: Name Description event.name The name of the emitted event. event.severity The severity of the event (Debug, Information, Warning, Error, Critical). pipeline.name The name of the pipeline corresponding to the resilience pipeline. pipeline.instance The instance name of the pipeline corresponding to the resilience pipeline. strategy.name The name of the strategy generating this event. operation.key The operation key associated with the call site. exception.type The full name of the exception assigned to the execution result (System.InvalidOperationException). Event names The event.name tag is reported by individual resilience strategies. The built-in strategies report the following events: OnRetry OnFallback OnHedging OnTimeout OnCircuitClosed OnCircuitOpened OnCircuitHalfOpened OnRateLimiterRejected Instrument: resilience.polly.strategy.attempt.duration Type: Histogram Unit: milliseconds Numerical type of measurement: double Description: Tracks the duration of execution attempts, produced by Retry and Hedging resilience strategies. Tags: Name Description event.name The name of the emitted event. Currently, the event name is always ExecutionAttempt. event.severity The severity of the event (Debug, Information, Warning, Error, Critical). pipeline.name The name of the pipeline corresponding to the resilience pipeline. pipeline.instance The instance name of the pipeline corresponding to the resilience pipeline. strategy.name The name of the strategy generating this event. operation.key The operation key associated with the call site. exception.type The full name of the exception assigned to the execution result (System.InvalidOperationException). attempt.number The execution attempt number, starting at 0 (0, 1, 2, etc.). attempt.handled Indicates if the execution outcome was handled. A handled outcome indicates execution failure and the need for retry (true, false). Instrument: resilience.polly.pipeline.duration Type: Histogram Unit: milliseconds Numerical type of measurement: double Description: Measures the duration of resilience pipelines. Tags: Name Description pipeline.name The name of the pipeline corresponding to the resilience pipeline. pipeline.instance The instance name of the pipeline corresponding to the resilience pipeline. operation.key The operation key associated with the call site. exception.type The full name of the exception assigned to the execution result (System.InvalidOperationException). Logs Logs are registered under the Polly logger name. Here are some examples of the logs: // This log is recorded whenever a resilience event occurs. EventId = 0 Resilience event occurred. EventName: '{EventName}', Source: '{PipelineName}/{PipelineInstance}/{StrategyName}', Operation Key: '{OperationKey}', Result: '{Result}' // This log is recorded when a resilience pipeline begins executing. EventId = 1 Resilience pipeline executing. Source: '{PipelineName}/{PipelineInstance}', Operation Key: '{OperationKey}' // This log is recorded when a resilience pipeline finishes execution. EventId = 2 Resilience pipeline executed. Source: '{PipelineName}/{PipelineInstance}', Operation Key: '{OperationKey}', Result: '{Result}', Execution Health: '{ExecutionHealth}', Execution Time: {ExecutionTime}ms // This log is recorded upon the completion of every execution attempt. EventId = 3 Execution attempt. Source: '{PipelineName}/{PipelineInstance}/{StrategyName}', Operation Key: '{OperationKey}', Result: '{Result}', Handled: '{Handled}', Attempt: '{Attempt}', Execution Time: '{ExecutionTimeMs}' Emitting telemetry events Each resilience strategy can generate telemetry data through the ResilienceStrategyTelemetry API. Polly encapsulates event details as TelemetryEventArguments and emits them via TelemetryListener. To leverage this telemetry data, users should assign a TelemetryListener instance to ResiliencePipelineBuilder.TelemetryListener and then consume the TelemetryEventArguments. For common scenarios, it is expected that users would make use of Polly.Extensions. This extension enables telemetry configuration through the ResiliencePipelineBuilder.ConfigureTelemetry(...) method, which processes TelemetryEventArguments to generate logs and metrics."
  },
  "advanced/testing.html": {
    "href": "advanced/testing.html",
    "title": "Testing | Polly",
    "keywords": "Testing This document explains how to test Polly's resilience pipelines. You should not test how the resilience pipelines operate internally, but rather test your own settings or custom delegates. To make the testing process simpler, Polly offers the Polly.Testing package. This package has a range of APIs designed to help you test the setup and combination of resilience pipelines in your user code. Usage Begin by adding the Polly.Testing package to your test project: dotnet add package Polly.Testing Use the GetPipelineDescriptor extension method to get the ResiliencePipelineDescriptor which provides details on the pipeline's composition: // Build your resilience pipeline. ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddRetry(new RetryStrategyOptions { MaxRetryAttempts = 4 }) .AddTimeout(TimeSpan.FromSeconds(1)) .Build(); // Retrieve the descriptor. ResiliencePipelineDescriptor descriptor = pipeline.GetPipelineDescriptor(); // Check the pipeline's composition with the descriptor. Assert.Equal(2, descriptor.Strategies.Count); // Verify the retry settings. var retryOptions = Assert.IsType<RetryStrategyOptions>(descriptor.Strategies[0].Options); Assert.Equal(4, retryOptions.MaxRetryAttempts); // Confirm the timeout settings. var timeoutOptions = Assert.IsType<TimeoutStrategyOptions>(descriptor.Strategies[1].Options); Assert.Equal(TimeSpan.FromSeconds(1), timeoutOptions.Timeout); The GetPipelineDescriptor extension method is also available for the generic ResiliencePipeline<T>: // Construct your resilience pipeline. ResiliencePipeline<string> pipeline = new ResiliencePipelineBuilder<string>() .AddRetry(new RetryStrategyOptions<string> { MaxRetryAttempts = 4 }) .AddTimeout(TimeSpan.FromSeconds(1)) .Build(); // Obtain the descriptor. ResiliencePipelineDescriptor descriptor = pipeline.GetPipelineDescriptor(); // Check the pipeline's composition with the descriptor. // ... Mocking ResiliencePipelineProvider<TKey> Consider the following code that might resemble a part of your project: // Represents an arbitrary API that needs resilience support public class MyApi { private readonly ResiliencePipeline _pipeline; // The value of pipelineProvider is injected via dependency injection public MyApi(ResiliencePipelineProvider<string> pipelineProvider) { _pipeline = pipelineProvider.GetPipeline(\"my-pipeline\"); } public async Task ExecuteAsync(CancellationToken cancellationToken) { await _pipeline.ExecuteAsync( static async token => { // Add your code here }, cancellationToken); } } // Extensions to incorporate MyApi into dependency injection public static class MyApiExtensions { public static IServiceCollection AddMyApi(this IServiceCollection services) { return services .AddResiliencePipeline(\"my-pipeline\", builder => { builder.AddRetry(new RetryStrategyOptions { MaxRetryAttempts = 4 }); }) .AddSingleton<MyApi>(); } } In the example above: The MyApi class is introduced, representing part of your application that requires resilience support. The AddMyApi extension method is also defined, which integrates MyApi into dependency injection (DI) and sets up the resilience pipeline it uses. For unit tests, if you want to assess the behavior of ExecuteAsync, it might not be practical to rely on the entire pipeline, especially since it could slow down tests during failure scenario evaluations. Instead, it's recommended to mock the ResiliencePipelineProvider<string> and return an empty pipeline: ResiliencePipelineProvider<string> pipelineProvider = Substitute.For<ResiliencePipelineProvider<string>>(); // Mock the pipeline provider to return an empty pipeline for testing pipelineProvider .GetPipeline(\"my-pipeline\") .Returns(ResiliencePipeline.Empty); // Use the mocked pipeline provider in your code var api = new MyApi(pipelineProvider); // You can now test the api This example leverages the NSubstitute library to mock the pipeline provider."
  },
  "api/index.html": {
    "href": "api/index.html",
    "title": "PLACEHOLDER | Polly",
    "keywords": "PLACEHOLDER docfx automatically generates this file when GitHub Pages are built."
  },
  "community/git-workflow.html": {
    "href": "community/git-workflow.html",
    "title": "Git Workflow | Polly",
    "keywords": "Git Workflow Our recommended process for working with Polly is: Fork our repository on GitHub Clone your fork locally Configure the upstream (git remote add upstream https://github.com/App-vNext/Polly.git) Switch to the default branch (i.e. main) using git checkout main Create a new local branch for your changes (git checkout -b my-branch). Work on your changes Rebase if required (see below) Push the branch up to GitHub (git push origin my-branch) Create a Pull Request on GitHub - the PR should target (have as base branch) the default branch (i.e. main). You should not work on a clone of the default branch, and you should not send a pull request from it - please always work from a branch. The reasons for this are detailed below. Learning Git Workflow For an introduction to Git, check out GitHub's Git Guide. For more information about GitHub Flow, please head over to the GitHub Flow documentation. Handling Updates from the default branch While you're working away in your branch, it's possible that one or more new commits have been added to the repository's default branch. If this happens you should: Stash any uncommitted changes you need to git checkout main git pull upstream main git checkout my-branch git rebase main Sync your fork (optional) - this makes sure your remote main branch is up to date This ensures that your history is \"clean\" i.e. you have one branch off from main followed by your changes in a straight line. Failing to do this ends up with several \"messy\" merges in your history, which we don't want. This is the reason why you should always work in a branch and you should never be working in, or sending pull requests from, main. Rebasing public commits is considered to be bad practice, which is why we ask you to rebase any updates from upstream/main. If you're working on a long running feature then you may want to do this quite often, rather than run the risk of potential merge issues further down the line. Sending a Pull Request While working on your feature you may well create several branches, which is fine, but before you send a pull request you should ensure that you have rebased back to a single \"feature branch\" - we care about your commits, and we care about your feature branch; but we don't care about how many or which branches you created while you were working on it. When you're ready to go you should confirm that you are up-to-date and rebased with upstream (see \"Handling Updates from the default branch\" above), and then: git push origin my-branch Send a descriptive Pull Request on GitHub - making sure you have selected the correct branch in the GitHub UI. It is not the end of the world if the commit history in your pull request ends up being messy - we can always squash it down to a single commit before merging. However, if you follow the steps above you should end up with a neater history."
  },
  "community/libraries-and-contributions.html": {
    "href": "community/libraries-and-contributions.html",
    "title": "3rd Party Libraries and Contributions | Polly",
    "keywords": "3rd Party Libraries and Contributions Fluent Assertions - A set of .NET extension methods that allow you to more naturally specify the expected outcome of a TDD or BDD-style test | Apache License 2.0 (Apache) xUnit.net - Free, open source, community-focused unit testing tool for the .NET Framework | Apache License 2.0 (Apache) Ian Griffith's TimedLock Steven van Deursen's ReadOnlyDictionary (until Polly v5.0.6) Stephen Cleary's AsyncEx library for AsyncSemaphore (supports BulkheadAsync policy for .NET 4.0 only) (until Polly v5.9.0) | MIT license @theraot's ExceptionDispatchInfo implementation for .NET 4.0 (supports Timeout policy for .NET4.0 only) (until Polly v5.9.0) including also a contribution by @migueldeicaza | Licensed under and distributed under Creative Commons Attribution Share Alike license per StackExchange Terms of Service Build powered by Cake and MinVer. Developers powered by Resharper, with thanks to JetBrains for OSS licensing. Acknowledgements lokad-shared-libraries - Helper assemblies originally for .NET 3.5 and Silverlight 2.0 which were developed as part of the Open Source effort by Lokad.com (discontinued) | New BSD License @michael-wolfenden - The creator and mastermind of Polly! @ghuntley - Portable Class Library implementation. @mauricedb - Initial async implementation. @robgibbens - Added existing async files to PCL project Hacko - Added extra NotOnCapturedContext call to prevent potential deadlocks when blocking on asynchronous calls @ThomasMentzel - Added ability to capture the results of executing a policy via ExecuteAndCapture @yevhen - Added full control of whether to continue on captured synchronization context or not @reisenberger - Added full async cancellation support @reisenberger - Added async support for ContextualPolicy @reisenberger - Added ContextualPolicy support for circuit-breaker @reisenberger - Extended circuit-breaker for public monitoring and control @reisenberger - Added ExecuteAndCapture support with arbitrary context data @kristianhald and @reisenberger - Added AdvancedCircuitBreaker @reisenberger - Allowed async onRetry delegates to async retry policies @Lumirris - Add new Polly.Net40Async project/package supporting async for .NET 4.0 via Microsoft.Bcl.Async @SteveCote - Added overloads to WaitAndRetry{Async} methods that accept an onRetry delegate which includes the attempt count. @reisenberger - Allowed policies to handle returned results; added strongly-typed policies Policy&lt;TResult&gt;. @christopherbahr - Added optimisation for circuit-breaker hot path. @Finity - Fixed circuit-breaker threshold bug. @reisenberger - Add some missing ExecuteAndCapture{Async} overloads. @brunolauze - Add CancellationToken support to synchronous executions (to support TimeoutPolicy). @reisenberger - Add PolicyWrap. @reisenberger - Add Fallback policy. @reisenberger - Add PolicyKeys and context to all policy executions, as bedrock for policy events and metrics tracking executions. @reisenberger, and contributions from @brunolauze - Add Bulkhead Isolation policy. @reisenberger - Add Timeout policy. @reisenberger - Fix .NET Standard 1.0 targeting. Remove PCL259 target. PCL259 support is provided via .NET Standard 1.0 target, going forward. @reisenberger - Fix CircuitBreaker HalfOpen state and cases when breakDuration is shorter than typical call timeout. Thanks to @vgouw and @kharos for the reports and insightful thinking. @lakario - Tidy CircuitBreaker LastException property. @lakario - Add NoOpPolicy. @Julien-Mialon - Fixes, support and examples for .NET Standard compatibility with Xamarin PCL projects @reisenberger - Add mutable Context and extra overloads taking Context. Allows different parts of a policy execution to exchange data via the mutable Context travelling with each execution. @ankitbko - Add PolicyRegistry for storing and retrieving policies. @reisenberger - Add interfaces by policy type and execution type. @seanfarrow - Add IReadOnlyPolicyRegistry interface. @kesmy - Migrate solution to msbuild15, banish project.json and packages.config @hambudi - Ensure sync TimeoutPolicy with TimeoutStrategy.Pessimistic rethrows delegate exceptions without additional AggregateException. @jiimaho and @Extremo75 - Provide public factory methods for PolicyResult, to support testing. @Extremo75 - Allow fallback delegates to take handled fault as input parameter. @reisenberger and @seanfarrow - Add CachePolicy, with interfaces for pluggable cache providers and serializers. Thanks to the awesome devs at @tretton37 who delivered the following as part of a one-day in-company hackathon led by @reisenberger, sponsored by @tretton37 and convened by @thecodejunkie @matst80 - Allow WaitAndRetry to take handled fault as an input to the sleepDurationProvider, allowing WaitAndRetry to take account of systems which specify a duration to wait as part of a fault response; e.g. Azure CosmosDB may specify this in x-ms-retry-after-ms headers or in a property to an exception thrown by the Azure CosmosDB SDK. @MartinSStewart - Add GetPolicies() extension methods to IPolicyWrap. @jbergens37 - Parallelize test running where possible, to improve overall build speed. @reisenberger - Add new .HandleInner<TException>(...) syntax for handling inner exceptions natively. @rjongeneelen and @reisenberger - Allow PolicyWrap configuration to configure policies via interfaces. @reisenberger - Performance improvements. @awarrenlove - Add ability to calculate cache TTL based on item to cache. @erickhouse - Add a new onBreak overload that provides the prior state on a transition to an open state. @benagain - Bug fix: RelativeTtl in CachePolicy now always returns a ttl relative to time item is cached. @urig - Allow TimeoutPolicy to be configured with Timeout.InfiniteTimeSpan. @reisenberger - Integration with IHttpClientFactory for ASP.NET Core 2.1. @freakazoid182 - WaitAndRetry{Forever} overloads where onRetry takes the retry number as a parameter. @dustyhoppe - Overloads where onTimeout takes thrown exception as a parameter. @flin-zap - Catch missing async continuation control. @reisenberger - Clarify separation of sync and async policies. @reisenberger - Enable extensibility by custom policies hosted external to Polly. @seanfarrow - Enable collection initialization syntax for PolicyRegistry. @moerwald - Code clean-ups, usage of more concise C# members. @cmeeren - Enable cache policies to cache values of default(TResult). @aprooks - Build script tweaks for Mac and Mono. @kesmy - Add SourceLink support, clean up cake build. @simluk - Fix continueOnCaptureContext not being honored in async retry implementation (bug in v7.1.0 only). @jnyrup - Upgrade tests to Fluent Assertions v5.9.0 @SimonCropp - Add netcoreapp3.0 target; code clean-ups. @aerotog and @reisenberger - IConcurrentPolicyRegistry methods on PolicyRegistry @reisenberger and @martincostello - Add RateLimit policy."
  },
  "community/polly-contrib.html": {
    "href": "community/polly-contrib.html",
    "title": "Polly-Contrib | Polly",
    "keywords": "Polly-Contrib Polly now has a Polly-Contrib to allow the community to contribute policies or other enhancements around Polly with a low burden of ceremony. Have a contribution you'd like to publish under Polly-Contrib? Contact us with an issue here or on Polly's Slack, and we can set up a CI-ready Polly.Contrib repository to which you have full rights, to help you manage and deliver your awesomeness to the community! We also provide: a blank starter template for a custom policy (see above for more on custom policies) a template repository for any other contributions Both templates contain a full project structure referencing Polly, Polly's default build targets, and a build to build and test your contrib and make a NuGet package. Available via Polly-Contrib Polly.Contrib.WaitAndRetry: a collection of concise helper methods for common wait-and-retry strategies; and a new jitter formula combining exponential back-off with a very even distribution of randomly-jittered retry intervals. Polly.Contrib.AzureFunctions.CircuitBreaker: a distributed circuit-breaker implemented in Azure Functions; consumable in Azure Functions, or from anywhere over http. Simmy: our chaos engineering project. Polly.Contrib.TimingPolicy: a starter policy to publish execution timings of any call executed through Policy. Polly.Contrib.LoggingPolicy: a policy simply to log handled exceptions/faults, and rethrow or bubble the fault outwards."
  },
  "community/resources.html": {
    "href": "community/resources.html",
    "title": "Resources | Polly",
    "keywords": "Resources This includes Blogs, podcasts, courses, e-books, architecture samples and videos around Polly. When we discover an interesting write-up on Polly, we'll add it to this list. If you have a blog post you'd like to share, please submit a PR! Blog posts Adding a circuit breaker to your ASP.NET 6 application with Polly - by Lachlan Barclay Try .NET Samples of Polly, the .NET Resilience Framework - by Bryan Hogan Create exceptional interactive documentation with Try .NET - The Polly NuGet library did! - by Scott Hanselman (writing about the work of Bryan Hogan) Adding resilience and Transient Fault handling to your .NET Core HttpClient with Polly - by Scott Hanselman Reliable Event Processing in Azure Functions - by Jeff Hollan Optimally configuring ASP.NET Core HttpClientFactory including with Polly policies - by Muhammad Rehan Saeed Integrating HttpClientFactory with Polly for transient fault handling - by Steve Gordon Resilient network connectivity in Xamarin Forms - by Adam Pedley Policy recommendations for Azure Cognitive Services - by Joel Hulen Using Polly with F# async workflows - by Mark Seemann Building resilient applications with Polly (with focus on Azure SQL transient errors) - by Geovanny Alzate Sandoval Azure SQL transient errors - by Mattias Karlsson Polly series on No Dogma blog - by Bryan Hogan Polly 5.0 - a wider resilience framework! - by Dylan Reisenberger Implementing the retry pattern in c sharp using Polly - by Alastair Crabtree NuGet Package of the Week: Polly wanna fluently express transient exception handling policies in .NET? - by Scott Hanselman Exception handling policies with Polly - by Mark Timmings When you use the Polly circuit-breaker, make sure you share your Policy instances! - by Andrew Lock Polly is Repetitive, and I love it! - by Joel Hulen Using the Context to Obtain the Retry Count for Diagnostics - by Steve Gordon Passing an ILogger to Polly Policies - by Steve Gordon Using Polly and Flurl to improve your website - by Jeremy Lindsay. Exploring the Polly.Contrib.WaitAndRetry helpers - by Ben Hyrman, who also wrote most of the Polly.Contrib.WaitAndRetry documentation. Retries - An interactive study of common retry methods - by Sam Rose Podcasts June 2018: DotNetRocks features Polly as Carl Franklin and Richard Campbell chat with Dylan Reisenberger about policy patterns, and the new ASP NET Core 2.1 integration with IHttpClientFactory. April 2017: Dylan Reisenberger sits down virtually with Bryan Hogan of No Dogma Blog for an Introduction to Polly podcast. Why do I need Polly? History of the Polly project. What do we mean by resilience and transient faults? How retry and circuit-breaker help. Exponential back-off. Stability patterns. Bulkhead isolation. Future directions (as at April 2017). PluralSight course Bryan Hogan of the No Dogma Blog has authored a PluralSight course on Polly. The course takes you through all the major features of Polly, with an additional module added in the fall of 2018 on HttpClientFactory. The course examples are based around using Polly for fault tolerance when calling remote web services, but the principles and techniques are applicable to any context in which Polly may be used. Sample micro-services architecture and e-book Sample micro-services architecture Cesar de la Torre produced the Microsoft eShopOnContainers project, a sample project demonstrating a .NET Micro-services architecture. The project uses Polly retry and circuit-breaker policies for resilience in calls to micro-services, and in establishing connections to transports such as RabbitMQ. e-book Accompanying the project is a .NET Micro-services Architecture e-book with an extensive section (section 8) on using Polly for resilience, to which Dylan Reisenberger contributed. The e-book and code is now (June 2018) updated for using the latest ASP NET Core 2.1 features, Polly with IHttpClientFactory. Videos Robust Applications with Polly, the .NET Resilience Framework, Bryan Hogan introduces Polly and explains how to use it to build a fault tolerant application. From MVP Houssem Dellai, a YouTube video on How to use Polly with Xamarin Apps, covering wait-and-retry and discussing circuit-breaker policy with a demonstration in Xamarin Forms. Here is the source code of the application demonstrated in the video. Draws on the ResilientHttpClient from Microsoft's eShopOnContainers project. In the video, .NET Rocks Live with Jon Skeet and Bill Wagner, Bill Wagner discusses Polly. Scott Allen discusses Polly during his Building for Resiliency and Scale in the Cloud presentation at NDC. ASP.NET Community Stand-up April 24, 2018: Damian Edwards, Jon Galloway and Scott Hanselman discuss Scott Hanselman's blog on Polly with IHttpClientFactory and the Polly team documentation on IHttpClientFactory. Interesting background discussion also on feature richness and the importance of good documentation."
  },
  "extensibility/index.html": {
    "href": "extensibility/index.html",
    "title": "Extensibility | Polly",
    "keywords": "Extensibility This article explains how to extend Polly with new resilience strategies. Polly identifies two types of resilience strategies: Reactive: These strategies handle specific exceptions that are thrown, or results that are returned, by the callbacks executed through the strategy. Proactive: Unlike reactive strategies, proactive strategies do not focus on handling errors by the callbacks might throw or return. They can make proactive decisions to cancel or reject the execution of callbacks (e.g., using a rate limiter or a timeout resilience strategy). This guide will help you create a new illustrative resilience strategy for each type. Basics of extensibility Regardless of whether the strategy is reactive or proactive, every new resilience strategy should include the following components: Options detailing the strategy's configuration. These should inherit from ResilienceStrategyOptions. Extensions for ResiliencePipelineBuilder or ResiliencePipelineBuilder<T>. Custom argument types for delegates that contain information about a specific event. The strategy options contain properties of following types: Common types: Such as int, bool, TimeSpan, etc. Delegates: For example when a strategy needs to raise an event, or generate a value. In general, the delegates should by asynchronous. Arguments: Used by the delegates to pass the information to their consumers. Delegates Individual resilience strategies make use of several delegate types: Predicates: Vital for determining whether a resilience strategy should handle the given execution result. Events: Triggered when significant actions or states occur within the resilience strategy. Generators: Invoked when the resilience strategy needs specific information or values from the caller. Recommended signatures for these delegates are: Predicates Func<Args<TResult>, ValueTask<bool>> (Reactive) Events Func<Args<TResult>, ValueTask> (Reactive) Func<Args, ValueTask> (Proactive) Generators Func<Args<TResult>, ValueTask<TValue>> (Reactive) Func<Args, ValueTask<TValue>> (Proactive) These delegates accept either Args or Args<TResult> arguments, which encapsulate event information. Note that all these delegates are asynchronous and return a ValueTask. Learn more about arguments in the sections below. Note When setting up delegates, consider using the ResilienceContext.ContinueOnCapturedContext property if your user code interacts with a synchronization context (such as in asynchronous UI applications like Windows Forms or WPF). How to use delegates Below are some examples illustrating the usage of these delegates: new ResiliencePipelineBuilder() .AddRetry(new RetryStrategyOptions { // Non-Generic predicate for multiple result types ShouldHandle = args => args.Outcome switch { { Exception: InvalidOperationException } => PredicateResult.True(), { Result: string result } when result == \"Failure\" => PredicateResult.True(), { Result: int result } when result == -1 => PredicateResult.True(), _ => PredicateResult.False() }, }) .Build(); new ResiliencePipelineBuilder<string>() .AddRetry(new RetryStrategyOptions<string> { // Generic predicate for a single result type ShouldHandle = args => args.Outcome switch { { Exception: InvalidOperationException } => PredicateResult.True(), { Result: { } result } when result == \"Failure\" => PredicateResult.True(), _ => PredicateResult.False() }, }) .Build(); Arguments Arguments are used by individual delegate types to flow information to the consumer. Arguments should always have an Arguments suffix and include a Context property. Using arguments boosts the extensibility and maintainability of the API, as adding new members becomes a non-breaking change. For proactive strategies, the arguments structure might resemble the following: // Structs for arguments encapsulate details about specific events within the resilience strategy. // Relevant properties to the event can be exposed. In this event, the actual execution time and the exceeded threshold are included. public readonly struct ThresholdExceededArguments { public ThresholdExceededArguments(ResilienceContext context, TimeSpan threshold, TimeSpan duration) { Context = context; Threshold = threshold; Duration = duration; } public TimeSpan Threshold { get; } public TimeSpan Duration { get; } // As per convention, all arguments should provide a \"Context\" property. public ResilienceContext Context { get; } } Implementing a resilience strategy To find out more details about implementing a strategy, follow the links below: Proactive strategy: Explains how to implement a proactive resilience strategy. Reactive strategy: Explains how to implement a reactive resilience strategy."
  },
  "extensibility/proactive-strategy.html": {
    "href": "extensibility/proactive-strategy.html",
    "title": "Proactive resilience strategy | Polly",
    "keywords": "Proactive resilience strategy This document guides you in creating a Timing resilience strategy that tracks the execution times of callbacks and reports when the execution time exceeds the expected duration. This is a prime example of a proactive strategy because we aren't concerned with the individual results produced by the callbacks. Hence, this strategy can be used across various result types. Implementation Proactive resilience strategies are derived from the ResilienceStrategy base class. For this strategy, the implementation is: // Strategies should be internal and not exposed in the library's public API. // Configure the strategy through extension methods and options. internal sealed class TimingResilienceStrategy : ResilienceStrategy { private readonly TimeSpan _threshold; private readonly Func<ThresholdExceededArguments, ValueTask>? _thresholdExceeded; private readonly ResilienceStrategyTelemetry _telemetry; public TimingResilienceStrategy( TimeSpan threshold, Func<ThresholdExceededArguments, ValueTask>? thresholdExceeded, ResilienceStrategyTelemetry telemetry) { _threshold = threshold; _telemetry = telemetry; _thresholdExceeded = thresholdExceeded; } protected override async ValueTask<Outcome<TResult>> ExecuteCore<TResult, TState>( Func<ResilienceContext, TState, ValueTask<Outcome<TResult>>> callback, ResilienceContext context, TState state) { var stopwatch = Stopwatch.StartNew(); // Execute the given callback and adhere to the ContinueOnCapturedContext property value. Outcome<TResult> outcome = await callback(context, state).ConfigureAwait(context.ContinueOnCapturedContext); if (stopwatch.Elapsed > _threshold) { // Bundle information about the event into arguments. var args = new ThresholdExceededArguments(context, _threshold, stopwatch.Elapsed); // Report this as a resilience event if the execution took longer than the threshold. _telemetry.Report( new ResilienceEvent(ResilienceEventSeverity.Warning, \"ExecutionThresholdExceeded\"), context, args); if (_thresholdExceeded is not null) { await _thresholdExceeded(args).ConfigureAwait(context.ContinueOnCapturedContext); } } // Return the outcome directly. return outcome; } } Review the code and comments to understand the implementation. Take note of the ThresholdExceededArguments struct: // Structs for arguments encapsulate details about specific events within the resilience strategy. // Relevant properties to the event can be exposed. In this event, the actual execution time and the exceeded threshold are included. public readonly struct ThresholdExceededArguments { public ThresholdExceededArguments(ResilienceContext context, TimeSpan threshold, TimeSpan duration) { Context = context; Threshold = threshold; Duration = duration; } public TimeSpan Threshold { get; } public TimeSpan Duration { get; } // As per convention, all arguments should provide a \"Context\" property. public ResilienceContext Context { get; } } Arguments should always have an Arguments suffix and include a Context property. Using arguments boosts the extensibility and maintainability of the API, as adding new members becomes a non-breaking change. The ThresholdExceededArguments provides details about the actual execution time and threshold, allowing consumers to respond to this event or supply a custom callback for such situations. Options In the previous section, we implemented the TimingResilienceStrategy. Now, it's time to integrate it with Polly and its public API. Let's define the public TimingStrategyOptions to configure our strategy: public class TimingStrategyOptions : ResilienceStrategyOptions { public TimingStrategyOptions() { // Assign a default name to the options for more detailed telemetry insights. Name = \"Timing\"; } // Apply validation attributes to guarantee the options' validity. // The pipeline will handle validation automatically during its construction. [Range(typeof(TimeSpan), \"00:00:00\", \"1.00:00:00\")] [Required] public TimeSpan? Threshold { get; set; } // Provide the delegate to be called when the threshold is surpassed. // Ideally, arguments should share the delegate's name, but with an \"Arguments\" suffix. public Func<ThresholdExceededArguments, ValueTask>? ThresholdExceeded { get; set; } } Options represent our public contract with the consumer. By using them, we can easily add new members without breaking changes and perform validation consistently. Extensions So far, we've covered: The public TimingStrategyOptions and its associated arguments. The proactive strategy implementation named TimingResilienceStrategy. The final step is to integrate these components with each other by adding new extensions for both ResiliencePipelineBuilder and ResiliencePipelineBuilder<T>. Since both builders inherit from the same base class, we can introduce a single extension for ResiliencePipelineBuilderBase to serve both. public static class TimingResilienceStrategyBuilderExtensions { // The extensions should return the builder to support a fluent API. // For proactive strategies, we can target both \"ResiliencePipelineBuilderBase\" and \"ResiliencePipelineBuilder<T>\" // using generic constraints. public static TBuilder AddTiming<TBuilder>(this TBuilder builder, TimingStrategyOptions options) where TBuilder : ResiliencePipelineBuilderBase { // Add the strategy through the AddStrategy method. This method accepts a factory delegate // and automatically validates the options. return builder.AddStrategy( context => { // The \"context\" provides various properties for the strategy's use. // In this case, we simply use the \"Telemetry\" property and pass it to the strategy. // The Threshold and ThresholdExceeded values are sourced from the options. var strategy = new TimingResilienceStrategy( options.Threshold!.Value, options.ThresholdExceeded, context.Telemetry); return strategy; }, options); } } Usage // Add the proactive strategy to the builder var pipeline = new ResiliencePipelineBuilder() // This is custom extension defined in this sample .AddTiming(new TimingStrategyOptions { Threshold = TimeSpan.FromSeconds(1), ThresholdExceeded = args => { Console.WriteLine(\"Execution threshold exceeded!\"); return default; }, }) .Build(); Resources For further information on proactive resilience strategies, consider exploring these resources: Timing strategy sample: A practical example from this guide. Timeout resilience strategy: Discover the built-in timeout resilience strategy implementation. Rate limiter resilience strategy: Discover how rate limiter strategy is implemented."
  },
  "extensibility/reactive-strategy.html": {
    "href": "extensibility/reactive-strategy.html",
    "title": "Reactive resilience strategy | Polly",
    "keywords": "Reactive resilience strategy This document describes how to set up a Result reporting resilience strategy. This strategy lets you listen for specific results and report them to other components. It serves as a good example of a reactive strategy because it deals with specific results. Implementation Reactive resilience strategies inherit from the ResilienceStrategy<T> base class. The implementation for this specific strategy is as follows: // Strategies should be internal and not exposed in the library's public API. // Use extension methods and options to configure the strategy. internal sealed class ResultReportingResilienceStrategy<T> : ResilienceStrategy<T> { private readonly Func<ResultReportingPredicateArguments<T>, ValueTask<bool>> _shouldHandle; private readonly Func<OnReportResultArguments<T>, ValueTask> _onReportResult; private readonly ResilienceStrategyTelemetry _telemetry; public ResultReportingResilienceStrategy( Func<ResultReportingPredicateArguments<T>, ValueTask<bool>> shouldHandle, Func<OnReportResultArguments<T>, ValueTask> onReportResult, ResilienceStrategyTelemetry telemetry) { _shouldHandle = shouldHandle; _onReportResult = onReportResult; _telemetry = telemetry; } protected override async ValueTask<Outcome<T>> ExecuteCore<TState>( Func<ResilienceContext, TState, ValueTask<Outcome<T>>> callback, ResilienceContext context, TState state) { Outcome<T> outcome = await callback(context, state).ConfigureAwait(context.ContinueOnCapturedContext); // Check if the outcome should be reported using the \"ShouldHandle\" predicate. if (await _shouldHandle(new ResultReportingPredicateArguments<T>(context, outcome)).ConfigureAwait(context.ContinueOnCapturedContext)) { var args = new OnReportResultArguments<T>(context, outcome); // Report the event with an informational severity level to the telemetry infrastructure. _telemetry.Report(new ResilienceEvent(ResilienceEventSeverity.Information, \"ResultReported\"), context, outcome, args); // Call the \"OnReportResult\" callback. await _onReportResult(args).ConfigureAwait(context.ContinueOnCapturedContext); } return outcome; } } Reactive strategies use the ShouldHandle predicate to decide whether to handle the outcome of a user callback. The convention is to name the predicate's arguments using the {StrategyName}PredicateArguments pattern and return a ValueTask<bool>. Here, we use ResultReportingPredicateArguments<TResult>: public struct ResultReportingPredicateArguments<TResult> { public ResultReportingPredicateArguments(ResilienceContext context, Outcome<TResult> outcome) { Context = context; Outcome = outcome; } // Always include the \"Context\" property in the arguments. public ResilienceContext Context { get; } // Always have the \"Outcome\" property in reactive arguments. public Outcome<TResult> Outcome { get; } } Reactive arguments always contain the Context and Outcome properties. Additionally, to report the outcome, the strategy uses OnReportResultArguments<TResult>: public struct OnReportResultArguments<TResult> { public OnReportResultArguments(ResilienceContext context, Outcome<TResult> outcome) { Context = context; Outcome = outcome; } // Always include the \"Context\" property in the arguments. public ResilienceContext Context { get; } // Always have the \"Outcome\" property in reactive arguments. public Outcome<TResult> Outcome { get; } } Using arguments in callbacks supports a more maintainable and extensible API. Options In the previous section, we implemented the ResultReportingResilienceStrategy<T>. Now, we need to integrate it with Polly and its public API. Define the public ResultReportingStrategyOptions<TResult> class to configure our strategy: public class ResultReportingStrategyOptions<TResult> : ResilienceStrategyOptions { public ResultReportingStrategyOptions() { // Set a default name for the options to enhance telemetry insights. Name = \"ResultReporting\"; } // Options for reactive strategies should always include a \"ShouldHandle\" delegate. // Set a sensible default when possible. Here, we handle all exceptions. public Func<ResultReportingPredicateArguments<TResult>, ValueTask<bool>> ShouldHandle { get; set; } = args => { return new ValueTask<bool>(args.Outcome.Exception is not null); }; // This illustrates an event delegate. Note that the arguments struct carries the same name as the delegate but with an \"Arguments\" suffix. // The event follows the async convention and must be set by the user. // // The [Required] attribute enforces the consumer to specify this property, used when some properties do not have sensible defaults and are required. [Required] public Func<OnReportResultArguments<TResult>, ValueTask>? OnReportResult { get; set; } } If you want to support non-generic options for the ResiliencePipelineBuilder, you can expose them as well: // Simply derive from the generic options, using 'object' as the result type. // This allows the strategy to manage all results. public class ResultReportingStrategyOptions : ResultReportingStrategyOptions<object> { } Using options as a public contract helps us ensure flexibility with consumers. By adopting this method, you can introduce new members with ease without introducing breaking changes and maintain consistent validation. Extensions Up until now, we've discussed: The public ResultReportingStrategyOptions<TResult> and the related arguments. The proactive strategy implementation called ResultReportingResilienceStrategy<TResult>. The next step is to combine these elements by introducing new extensions for ResiliencePipelineBuilder<T> and, optionally, ResiliencePipelineBuilder. public static class ResultReportingResilienceStrategyBuilderExtensions { // Add extensions for the generic builder. // Extensions should return the builder to support a fluent API. public static ResiliencePipelineBuilder<TResult> AddResultReporting<TResult>(this ResiliencePipelineBuilder<TResult> builder, ResultReportingStrategyOptions<TResult> options) { // Incorporate the strategy using the AddStrategy() method. This method receives a factory delegate // and automatically checks the options. return builder.AddStrategy( context => { // The \"context\" offers various properties for the strategy to use. // Here, we simply use the \"Telemetry\" property and hand it over to the strategy. // The ShouldHandle and OnReportResult values come from the options. var strategy = new ResultReportingResilienceStrategy<TResult>( options.ShouldHandle, options.OnReportResult!, context.Telemetry); return strategy; }, options); } // Optionally, if suitable for the strategy, add support for non-generic builders. // Observe the use of the non-generic ResultReportingStrategyOptions. public static ResiliencePipelineBuilder AddResultReporting(this ResiliencePipelineBuilder builder, ResultReportingStrategyOptions options) { return builder.AddStrategy( context => { var strategy = new ResultReportingResilienceStrategy<object>( options.ShouldHandle, options.OnReportResult!, context.Telemetry); return strategy; }, options); } } Usage // Add reactive strategy to the builder new ResiliencePipelineBuilder<HttpResponseMessage>() .AddResultReporting(new ResultReportingStrategyOptions<HttpResponseMessage> { // Define what outcomes to handle ShouldHandle = args => args.Outcome switch { { Exception: { } } => PredicateResult.True(), { Result: { StatusCode: HttpStatusCode.InternalServerError } } => PredicateResult.True(), _ => PredicateResult.False() }, OnReportResult = args => { Console.WriteLine($\"Result: {args.Outcome}\"); return default; } }); // You can also use the non-generic ResiliencePipelineBuilder to handle any kind of result. new ResiliencePipelineBuilder() .AddResultReporting(new ResultReportingStrategyOptions { // Define what outcomes to handle ShouldHandle = args => args.Outcome switch { { Exception: { } } => PredicateResult.True(), { Result: HttpResponseMessage message } when message.StatusCode == HttpStatusCode.InternalServerError => PredicateResult.True(), _ => PredicateResult.False() }, OnReportResult = args => { Console.WriteLine($\"Result: {args.Outcome}\"); return default; } }); Resources For further information about reactive resilience strategies, consider exploring these resources: Result reporting strategy sample: A practical example from this guide. Retry resilience strategy: Discover the built-in retry resilience strategy implementation. Fallback resilience strategy: Discover the built-in fallback resilience strategy implementation."
  },
  "general.html": {
    "href": "general.html",
    "title": "General | Polly",
    "keywords": "General Supported targets Polly targets .NET Standard 2.0+ (coverage: .NET Core 2.0+, .NET Core 3.0, .NET 6.0+ and later Mono, Xamarin and UWP targets). The NuGet package also includes direct targets for .NET Framework 4.6.1 and 4.7.2. For details of supported compilation targets by version, see the supported targets grid. Asynchronous support Polly provides native support for asynchronous operations through all its resilience strategies by offering the ExecuteAsync methods on the ResiliencePipeline class. SynchronizationContext By default, asynchronous continuations and retries do not execute on a captured synchronization context. To modify this behavior, you can use the ResilienceContext class and set its ContinueOnCapturedContext property to true. The following example illustrates this: // Retrieve an instance of ResilienceContext from the pool // with the ContinueOnCapturedContext property set to true ResilienceContext context = ResilienceContextPool.Shared.Get(continueOnCapturedContext: true); await pipeline.ExecuteAsync( static async context => { // Execute your code, honoring the ContinueOnCapturedContext setting await MyMethodAsync(context.CancellationToken).ConfigureAwait(context.ContinueOnCapturedContext); }, context); // Optionally, return the ResilienceContext instance back to the pool // to minimize allocations and enhance performance ResilienceContextPool.Shared.Return(context); Cancellation support Asynchronous pipeline execution in Polly supports cancellation. This is facilitated through the ExecuteAsync(...) method overloads that accept a CancellationToken, or by initializing the ResilienceContext class with the CancellationToken property. The CancellationToken you pass to the ExecuteAsync(...) method serves multiple functions: It cancels resilience actions such as retries, wait times between retries, or rate-limiter leases. It is passed to any delegate executed by the strategy as a CancellationToken parameter, enabling cancellation during the delegate's execution. Is consistent with the .NET Base Class Library's (BCL) behavior in Task.Run(...), if the cancellation token is cancelled before execution begins, the user-defined delegate will not execute at all. // Execute your code with cancellation support await pipeline.ExecuteAsync( static async token => await MyMethodAsync(token), cancellationToken); // Use ResilienceContext for more advanced scenarios ResilienceContext context = ResilienceContextPool.Shared.Get(cancellationToken: cancellationToken); await pipeline.ExecuteAsync( static async context => await MyMethodAsync(context.CancellationToken), context); Thread safety All Polly resilience strategies are fully thread-safe. You can safely re-use strategies at multiple call sites, and execute through strategies concurrently on different threads. Important While the internal operation of the strategy is thread-safe, this does not automatically make delegates you execute through the strategy thread-safe: if delegates you execute through the strategy are not thread-safe, they remain not thread-safe."
  },
  "getting-started.html": {
    "href": "getting-started.html",
    "title": "Getting started | Polly",
    "keywords": "Getting started To use Polly, you must provide a callback and execute it using a resilience pipeline. A resilience pipeline is a combination of one or more resilience strategies such as retry, timeout, and rate limiter. Polly uses builders to integrate these strategies into a pipeline. To get started, first add the Polly.Core package to your project by running the following command: dotnet add package Polly.Core You can create a ResiliencePipeline using the ResiliencePipelineBuilder class as shown below: // Create a instance of builder that exposes various extensions for adding resilience strategies ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddRetry(new RetryStrategyOptions()) // Add retry using the default options .AddTimeout(TimeSpan.FromSeconds(10)) // Add 10 second timeout .Build(); // Builds the resilience pipeline // Execute the pipeline asynchronously await pipeline.ExecuteAsync(static async cancellationToken => { /*Your custom logic here */ }, cancellationToken); Dependency injection If you prefer to define resilience pipelines using IServiceCollection, you'll need to install the Polly.Extensions package: dotnet add package Polly.Extensions You can then define your resilience pipeline using the AddResiliencePipeline(...) extension method as shown: var services = new ServiceCollection(); // Define a resilience pipeline with the name \"my-pipeline\" services.AddResiliencePipeline(\"my-pipeline\", builder => { builder .AddRetry(new RetryStrategyOptions()) .AddTimeout(TimeSpan.FromSeconds(10)); }); // Build the service provider IServiceProvider serviceProvider = services.BuildServiceProvider(); // Retrieve ResiliencePipelineProvider that caches and dynamically creates the resilience pipelines var pipelineProvider = serviceProvider.GetRequiredService<ResiliencePipelineProvider<string>>(); // Retrieve resilience pipeline using the name it was registered with ResiliencePipeline pipeline = pipelineProvider.GetPipeline(\"my-pipeline\"); // Execute the pipeline await pipeline.ExecuteAsync(static async token => { // Your custom logic here });"
  },
  "index.html": {
    "href": "index.html",
    "title": "Meet Polly: The .NET resilience library | Polly",
    "keywords": "Meet Polly: The .NET resilience library Polly is a powerful library for .NET that helps you handle transient faults and improve the resilience of your applications. With Polly, you can easily define and apply strategies such as Retry, Circuit Breaker, Hedging, Timeout, Rate Limiter and Fallback to handle failures and slowdowns in a fluent and thread-safe way. Polly is part of the .NET Foundation! What can Polly do for you? Polly lets you use and combine different resilience strategies to cope with various scenarios, such as: Retry: Try again if something fails. This can be useful when the problem is temporary and might go away. Circuit Breaker: Stop trying if something is broken or busy. This can benefit you by avoiding wasting time and making things worse. It can also support the system to recover. Timeout: Give up if something takes too long. This can improve your performance by freeing up space and resources. Rate Limiter: Limit how many requests you make or accept. This can enable you to control the load and prevent problems or penalties. Fallback: Do something else if something fails. This can improve your user experience and keep the program working. Hedging: Do more than one thing at the same time and take the fastest one. This can make your program faster and more responsive. You can learn more about each strategy and how to use them resilience strategies section. How to get started with Polly? Polly is easy to install and use. You can follow the getting started guide to add and start using Polly in your projects. Where to find more information? Polly has a rich documentation that covers various topics, such as: Resilience strategies: A collection of strategies for improving the resilience of your system. Resilience pipelines: How to combine and reuse strategies in a flexible and modular way. Telemetry and monitoring: How to access and analyze the data generated by Polly strategies and pipelines. Dependency injection: How to integrate Polly with dependency injection frameworks and containers. Performance: Tips on optimizing and getting the best performance from Polly. Testing: How to test the composition and configuration of resilience pipelines. Chaos engineering: How to use Polly to inject faults and test the resilience of your system. Extensibility: How to create and use custom strategies and extensions for Polly. You can also find many resources and community contributions, such as: Samples: Samples in this repository that serve as an introduction to Polly. Practical Samples: Practical examples for using various implementations of Polly. Please feel free to contribute to the Polly-Samples repository in order to assist others who are either learning Polly for the first time, or are seeking advanced examples and novel approaches provided by our generous community. Polly-Contrib: Community projects and libraries that extend and enhance Polly's functionality and ecosystem. Libraries and contributions: Dependencies and contributors that make Polly possible and awesome. Microsoft's eShopOnContainers project: Sample project demonstrating a .NET Micro-services architecture and using Polly for resilience. Git Workflow: Our suggested Git workflow for contributing to Polly. You can browse the documentation using the sidebar or visit the API section for the reference documentation."
  },
  "migration-v8.html": {
    "href": "migration-v8.html",
    "title": "Migration guide from v7 to v8 | Polly",
    "keywords": "Migration guide from v7 to v8 Welcome to the migration guide for Polly's v8 release. Version 8 of Polly brings major new enhancements and supports all of the same scenarios as previous versions. In the following sections, we'll detail the differences between the v7 and v8 APIs, and provide steps on how to transition smoothly. Note The v7 API is still available and fully supported even when using the v8 version by referencing the Polly package. Major differences The term Policy is now replaced with Strategy: In previous versions, Polly used the term policy for retries, timeouts, etc. In v8, these are referred to as resilience strategies. Introduction of Resilience Pipelines: A resilience pipeline combines one or more resilience strategies. This is the foundational API for Polly v8, similar to the Policy Wrap in previous versions but integrated into the core API. Unified sync and async flows: Interfaces such as IAsyncPolicy, IAsyncPolicy<T>, ISyncPolicy, ISyncPolicy<T>, and IPolicy are now unified under ResiliencePipeline and ResiliencePipeline<T>. The resilience pipeline supports both synchronous and asynchronous execution flows. Native async support: Polly v8 was designed with asynchronous support from the start. No static APIs: Unlike previous versions, v8 doesn't use static APIs. This improves testability and extensibility while maintaining ease of use. Options-based configuration: Configuring individual resilience strategies is now options-based, offering more flexibility and improving maintainability and extensibility. Built-in telemetry: Polly v8 now has built-in telemetry support. Improved performance and low-allocation APIs: Polly v8 brings significant performance enhancements and provides zero-allocation APIs for advanced use cases. Note Please read the comments in the code carefully for additional context and explanations. Migrating execution policies This section describes how to migrate from execution policies (i.e. IAsyncPolicy, ISyncPolicy) to resilience pipelines (i.e. ResiliencePipeline, ResiliencePipeline<T>). Configuring policies in v7 In earlier versions, Polly exposed various interfaces to execute user code: IAsyncPolicy IAsyncPolicy<T> ISyncPolicy ISyncPolicy<T> These interfaces were created and used as shown below: // Create and use the ISyncPolicy. ISyncPolicy syncPolicy = Policy.Handle<Exception>().WaitAndRetry(3, _ => TimeSpan.FromSeconds(1)); syncPolicy.Execute(() => { // Your code here }); // Create and use the IAsyncPolicy IAsyncPolicy asyncPolicy = Policy.Handle<Exception>().WaitAndRetryAsync(3, _ => TimeSpan.FromSeconds(1)); await asyncPolicy.ExecuteAsync( async cancellationToken => { // Your code here }, cancellationToken); // Create and use the ISyncPolicy<T> ISyncPolicy<HttpResponseMessage> syncPolicyT = Policy .HandleResult<HttpResponseMessage>(r => !r.IsSuccessStatusCode) .WaitAndRetry(3, _ => TimeSpan.FromSeconds(1)); syncPolicyT.Execute(() => { // Your code here return GetResponse(); }); // Create and use the IAsyncPolicy<T> IAsyncPolicy<HttpResponseMessage> asyncPolicyT = Policy .HandleResult<HttpResponseMessage>(r => !r.IsSuccessStatusCode) .WaitAndRetryAsync(3, _ => TimeSpan.FromSeconds(1)); await asyncPolicyT.ExecuteAsync( async cancellationToken => { // Your code here return await GetResponseAsync(cancellationToken); }, cancellationToken); Configuring strategies in v8 In Polly v8, the previous code becomes: // Create and use the ResiliencePipeline. // // The ResiliencePipelineBuilder is used to start building the resilience pipeline, // instead of the static Policy.HandleException<TException>() call. ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddRetry(new RetryStrategyOptions { ShouldHandle = new PredicateBuilder().Handle<Exception>(), Delay = TimeSpan.FromSeconds(1), MaxRetryAttempts = 3, BackoffType = DelayBackoffType.Constant }) .Build(); // After all necessary strategies are added, call Build() to create the pipeline. // Synchronous execution pipeline.Execute(() => { // Your code here }); // Asynchronous execution is also supported with the same pipeline instance await pipeline.ExecuteAsync(static async cancellationToken => { // Your code here }, cancellationToken); // Create and use the ResiliencePipeline<T>. // // Building of generic resilience pipeline is very similar to non-generic one. // Notice the use of generic RetryStrategyOptions<HttpResponseMessage> to configure the strategy // as opposed to providing the arguments into the method. ResiliencePipeline<HttpResponseMessage> pipelineT = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddRetry(new RetryStrategyOptions<HttpResponseMessage> { ShouldHandle = new PredicateBuilder<HttpResponseMessage>() .Handle<Exception>() .HandleResult(result => !result.IsSuccessStatusCode), Delay = TimeSpan.FromSeconds(1), MaxRetryAttempts = 3, BackoffType = DelayBackoffType.Constant }) .Build(); // Synchronous execution pipelineT.Execute(() => { // Your code here return GetResponse(); }); // Asynchronous execution await pipelineT.ExecuteAsync(static async cancellationToken => { // Your code here return await GetResponseAsync(cancellationToken); }, cancellationToken); Migrating policy wrap Policy wrap in v7 Policy wrap is used to combine multiple policies into one as shown in the v7 example below: IAsyncPolicy retryPolicy = Policy.Handle<Exception>().WaitAndRetryAsync(3, _ => TimeSpan.FromSeconds(1)); IAsyncPolicy timeoutPolicy = Policy.TimeoutAsync(TimeSpan.FromSeconds(3)); // Wrap the policies. The policies are executed in the following order (i.e. Last-In-First-Out): // 1. Retry // 2. Timeout IAsyncPolicy wrappedPolicy = Policy.WrapAsync(timeoutPolicy, retryPolicy); Policy wrap in v8 In v8, there's no need to use policy wrap explicitly. Instead, policy wrapping is integrated into ResiliencePipelineBuilder, as shown in the example below: // The \"PolicyWrap\" is integrated directly. Strategies are executed in the same order as they were added (i.e. First-In-First-Out): // 1. Retry // 2. Timeout ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddRetry(new() { MaxRetryAttempts = 3, Delay = TimeSpan.FromSeconds(1), BackoffType = DelayBackoffType.Constant, ShouldHandle = new PredicateBuilder().Handle<Exception>() }) .AddTimeout(TimeSpan.FromSeconds(3)) .Build(); Important In v7, the policy wrap ordering is different; the policy added first was executed last (FILO). In v8, the execution order matches the order in which they were added (FIFO). See fallback after retries for an example on how the strategies are executed. Migrating retry policies This section describes how to migrate the v7 retry policy to a resilience strategy in v8. Retry in v7 In v7 the retry policy is configured as: // Retry once Policy .Handle<SomeExceptionType>() .Retry(); // Retry multiple times Policy .Handle<SomeExceptionType>() .Retry(3); // Retry multiple times with callback Policy .Handle<SomeExceptionType>() .Retry(3, onRetry: (exception, retryCount) => { // Add logic to be executed before each retry, such as logging }); Retry in v8 In v8 the retry strategy is configured as: // Retry once // // Because we are adding retries to a non-generic pipeline, // we use the non-generic RetryStrategyOptions. new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { // PredicateBuilder is used to simplify the initialization of predicates. // Its API should be familiar to the v7 way of configuring what exceptions to handle. ShouldHandle = new PredicateBuilder().Handle<SomeExceptionType>(), MaxRetryAttempts = 1, // To disable waiting between retries, set the Delay property to TimeSpan.Zero. Delay = TimeSpan.Zero, }) .Build(); // Retry multiple times new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { ShouldHandle = new PredicateBuilder().Handle<SomeExceptionType>(), MaxRetryAttempts = 3, Delay = TimeSpan.Zero, }) .Build(); // Retry multiple times with callback new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { ShouldHandle = new PredicateBuilder().Handle<SomeExceptionType>(), MaxRetryAttempts = 3, Delay = TimeSpan.Zero, OnRetry = args => { // Add logic to be executed before each retry, such as logging return default; } }) .Build(); // Retry forever new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { ShouldHandle = new PredicateBuilder().Handle<SomeExceptionType>(), // To retry forever, set the MaxRetryAttempts property to int.MaxValue. MaxRetryAttempts = int.MaxValue, Delay = TimeSpan.Zero, }) .Build(); Retry and wait in v7 // Retry forever Policy .Handle<SomeExceptionType>() .WaitAndRetryForever(_ => TimeSpan.FromSeconds(1)); // Wait and retry multiple times Policy .Handle<SomeExceptionType>() .WaitAndRetry(3, _ => TimeSpan.FromSeconds(1)); // Wait and retry multiple times with callback Policy .Handle<SomeExceptionType>() .WaitAndRetry(3, _ => TimeSpan.FromSeconds(1), onRetry: (exception, retryCount) => { // Add logic to be executed before each retry, such as logging }); // Wait and retry forever Policy .Handle<SomeExceptionType>() .WaitAndRetryForever(_ => TimeSpan.FromSeconds(1)); Retry and wait in v8 // Wait and retry multiple times new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { ShouldHandle = new PredicateBuilder().Handle<SomeExceptionType>(), MaxRetryAttempts = 3, Delay = TimeSpan.FromSeconds(1), BackoffType = DelayBackoffType.Constant }) .Build(); // Wait and retry multiple times with callback new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { ShouldHandle = new PredicateBuilder().Handle<SomeExceptionType>(), MaxRetryAttempts = 3, Delay = TimeSpan.FromSeconds(1), BackoffType = DelayBackoffType.Constant, OnRetry = args => { // Add logic to be executed before each retry, such as logging return default; } }) .Build(); // Wait and retry forever new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { ShouldHandle = new PredicateBuilder().Handle<SomeExceptionType>(), MaxRetryAttempts = int.MaxValue, Delay = TimeSpan.FromSeconds(1), BackoffType = DelayBackoffType.Constant }) .Build(); Retry results in v7 // Wait and retry with result handling Policy .Handle<SomeExceptionType>() .OrResult<HttpResponseMessage>(response => response.StatusCode == HttpStatusCode.InternalServerError) .WaitAndRetry(3, _ => TimeSpan.FromSeconds(1)); Retry results in v8 // Shows how to add a retry strategy that also retries particular results. new ResiliencePipelineBuilder<HttpResponseMessage>().AddRetry(new RetryStrategyOptions<HttpResponseMessage> { // PredicateBuilder is a convenience API that can used to configure the ShouldHandle predicate. ShouldHandle = new PredicateBuilder<HttpResponseMessage>() .Handle<SomeExceptionType>() .HandleResult(result => result.StatusCode == HttpStatusCode.InternalServerError), MaxRetryAttempts = 3, }) .Build(); // The same as above, but using the switch expressions for best performance. new ResiliencePipelineBuilder<HttpResponseMessage>().AddRetry(new RetryStrategyOptions<HttpResponseMessage> { // Determine what results to retry using switch expressions. // Note that PredicateResult.True() is just a shortcut for \"new ValueTask<bool>(true)\". ShouldHandle = args => args.Outcome switch { { Exception: SomeExceptionType } => PredicateResult.True(), { Result: { StatusCode: HttpStatusCode.InternalServerError } } => PredicateResult.True(), _ => PredicateResult.False() }, MaxRetryAttempts = 3, }) .Build(); It's important to remember that the configuration in v8 is options based, i.e. RetryStrategyOptions are used. Migrating rate limit policies The rate limit policy is now replaced by the rate limiter strategy which uses the System.Threading.RateLimiting package. Polly does not implement its own rate limiter anymore. Rate limit in v7 // Create sync rate limiter ISyncPolicy syncPolicy = Policy.RateLimit( numberOfExecutions: 100, perTimeSpan: TimeSpan.FromMinutes(1)); // Create async rate limiter IAsyncPolicy asyncPolicy = Policy.RateLimitAsync( numberOfExecutions: 100, perTimeSpan: TimeSpan.FromMinutes(1)); // Create generic sync rate limiter ISyncPolicy<HttpResponseMessage> syncPolicyT = Policy.RateLimit<HttpResponseMessage>( numberOfExecutions: 100, perTimeSpan: TimeSpan.FromMinutes(1)); // Create generic async rate limiter IAsyncPolicy<HttpResponseMessage> asyncPolicyT = Policy.RateLimitAsync<HttpResponseMessage>( numberOfExecutions: 100, perTimeSpan: TimeSpan.FromMinutes(1)); Rate limit in v8 Note In v8, you have to add the Polly.RateLimiting package to your application otherwise you won't see the AddRateLimiter extension. // The equivalent to Polly v7's RateLimit is the SlidingWindowRateLimiter. // // Polly exposes just a simple wrapper to the APIs exposed by the System.Threading.RateLimiting APIs. // There is no need to create separate instances for sync and async flows as ResiliencePipeline handles both scenarios. ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddRateLimiter(new SlidingWindowRateLimiter(new SlidingWindowRateLimiterOptions { PermitLimit = 100, Window = TimeSpan.FromMinutes(1), })) .Build(); // The creation of generic pipeline is almost identical. // // Polly exposes the same set of rate-limiter extensions for both ResiliencePipeline<HttpResponseMessage> and ResiliencePipeline. ResiliencePipeline<HttpResponseMessage> pipelineT = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddRateLimiter(new SlidingWindowRateLimiter(new SlidingWindowRateLimiterOptions { PermitLimit = 100, Window = TimeSpan.FromMinutes(1), })) .Build(); Migrating bulkhead policies The bulkhead policy is now replaced by the rate limiter strategy which uses the System.Threading.RateLimiting package. The new counterpart to bulkhead is ConcurrencyLimiter. Note In v7, the bulkhead was presented as an individual strategy. In v8, it's not separately exposed because it's essentially a specialized type of rate limiter: the ConcurrencyLimiter. Bulkhead in v7 // Create sync bulkhead ISyncPolicy syncPolicy = Policy.Bulkhead(maxParallelization: 100, maxQueuingActions: 50); // Create async bulkhead IAsyncPolicy asyncPolicy = Policy.BulkheadAsync(maxParallelization: 100, maxQueuingActions: 50); // Create generic sync bulkhead ISyncPolicy<HttpResponseMessage> syncPolicyT = Policy.Bulkhead<HttpResponseMessage>(maxParallelization: 100, maxQueuingActions: 50); // Create generic async bulkhead IAsyncPolicy<HttpResponseMessage> asyncPolicyT = Policy.BulkheadAsync<HttpResponseMessage>(maxParallelization: 100, maxQueuingActions: 50); Bulkhead in v8 Note In v8, you have to add the Polly.RateLimiting package to your application otherwise you won't see the AddConcurrencyLimiter extension. // Create pipeline with concurrency limiter. Because ResiliencePipeline supports both sync and async // callbacks, there is no need to define it twice. ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddConcurrencyLimiter(permitLimit: 100, queueLimit: 50) .Build(); // Create a generic pipeline with concurrency limiter. Because ResiliencePipeline<T> supports both sync and async // callbacks, there is no need to define it twice. ResiliencePipeline<HttpResponseMessage> pipelineT = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddConcurrencyLimiter(permitLimit: 100, queueLimit: 50) .Build(); Migrating timeout policies Note In v8, the timeout resilience strategy does not support pessimistic timeouts because they can cause thread-pool starvation and non-cancellable background tasks. To address this, you can use this workaround to make the action cancellable. Timeout in v7 // Create sync timeout ISyncPolicy syncPolicy = Policy.Timeout(TimeSpan.FromSeconds(10)); // Create async timeout IAsyncPolicy asyncPolicy = Policy.TimeoutAsync(TimeSpan.FromSeconds(10)); // Create generic sync timeout ISyncPolicy<HttpResponseMessage> syncPolicyT = Policy.Timeout<HttpResponseMessage>(TimeSpan.FromSeconds(10)); // Create generic async timeout IAsyncPolicy<HttpResponseMessage> asyncPolicyT = Policy.TimeoutAsync<HttpResponseMessage>(TimeSpan.FromSeconds(10)); Timeout in v8 // Create pipeline with timeout. Because ResiliencePipeline supports both sync and async // callbacks, there is no need to define it twice. ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddTimeout(TimeSpan.FromSeconds(10)) .Build(); // Create a generic pipeline with timeout. Because ResiliencePipeline<T> supports both sync and async // callbacks, there is no need to define it twice. ResiliencePipeline<HttpResponseMessage> pipelineT = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddTimeout(TimeSpan.FromSeconds(10)) .Build(); Migrating other policies Migrating is a process similar to the ones described in the previous sections. Keep in mind that: Strategy configurations (or policies in v7) are now in options. Property names should match the v7 APIs and scenarios. Use ResiliencePipelineBuilder or ResiliencePipelineBuilder<T> and their respective extensions to add specific strategies. For more details on each strategy, refer to the resilience strategies documentation. Migrating Polly.Context Polly.Context has been succeeded by ResilienceContext. Here are the main changes: ResilienceContext is pooled for enhanced performance and cannot be directly created. Instead, use the ResilienceContextPool class to get an instance. Directly attaching custom data is supported by Context, whereas ResilienceContext employs the ResilienceContext.Properties property. Both PolicyKey and PolicyWrapKey are no longer a part of ResilienceContext. They've been relocated to ResiliencePipelineBuilder and are now used for telemetry. The CorrelationId property has been removed. For similar functionality, you can either use System.Diagnostics.Activity.Current.Id or attach your custom Id using ResilienceContext.Properties. Additionally, ResilienceContext introduces the CancellationToken property. Context in v7 // Create context Context context = new Context(); // Create context with operation key context = new Context(\"my-operation-key\"); // Attach custom properties context[\"prop-1\"] = \"value-1\"; context[\"prop-2\"] = 100; // Retrieve custom properties string value1 = (string)context[\"prop-1\"]; int value2 = (int)context[\"prop-2\"]; ResilienceContext in v8 // Create context ResilienceContext context = ResilienceContextPool.Shared.Get(); // Create context with operation key context = ResilienceContextPool.Shared.Get(\"my-operation-key\"); // Attach custom properties context.Properties.Set(new ResiliencePropertyKey<string>(\"prop-1\"), \"value-1\"); context.Properties.Set(new ResiliencePropertyKey<int>(\"prop-2\"), 100); // Retrieve custom properties string value1 = context.Properties.GetValue(new ResiliencePropertyKey<string>(\"prop-1\"), \"default\"); int value2 = context.Properties.GetValue(new ResiliencePropertyKey<int>(\"prop-2\"), 0); // Return the context to the pool ResilienceContextPool.Shared.Return(context); For more details, refer to the Resilience Context documentation. Migrating safe execution In v7, the ExecuteAndCapture{Async} methods are considered the safe counterpart of the Execute{Async}. The former does not throw an exception in case of failure rather than wrap the outcome in a result object. In v8, the ExecuteOutcomeAsync method should be used to execute the to-be-decorated method in a safe way. ExecuteAndCapture{Async} in V7 // Synchronous execution ISyncPolicy<int> syncPolicy = Policy.Timeout<int>(TimeSpan.FromSeconds(1)); PolicyResult<int> policyResult = syncPolicy.ExecuteAndCapture(Method); // Asynchronous execution IAsyncPolicy<int> asyncPolicy = Policy.TimeoutAsync<int>(TimeSpan.FromSeconds(1)); PolicyResult<int> asyncPolicyResult = await asyncPolicy.ExecuteAndCaptureAsync(MethodAsync, CancellationToken.None); // Assess policy result if (policyResult.Outcome == OutcomeType.Successful) { int result = policyResult.Result; // Process result } else { Exception exception = policyResult.FinalException; FaultType failtType = policyResult.FaultType!.Value; ExceptionType exceptionType = policyResult.ExceptionType!.Value; // Process failure } // Access context IAsyncPolicy<int> asyncPolicyWithContext = Policy.TimeoutAsync<int>(TimeSpan.FromSeconds(10), onTimeoutAsync: (ctx, ts, task) => { ctx[\"context_key\"] = \"context_value\"; return Task.CompletedTask; }); asyncPolicyResult = await asyncPolicyWithContext.ExecuteAndCaptureAsync((ctx, token) => MethodAsync(token), new Context(), CancellationToken.None); string? ctxValue = asyncPolicyResult.Context.GetValueOrDefault(\"context_key\") as string; ExecuteOutcomeAsync in V8 ResiliencePipeline<int> pipeline = new ResiliencePipelineBuilder<int>() .AddTimeout(TimeSpan.FromSeconds(1)) .Build(); // Synchronous execution // Polly v8 does not provide an API to synchronously execute and capture the outcome of a pipeline // Asynchronous execution var context = ResilienceContextPool.Shared.Get(); Outcome<int> pipelineResult = await pipeline.ExecuteOutcomeAsync( static async (ctx, state) => Outcome.FromResult(await MethodAsync(ctx.CancellationToken)), context, \"state\"); ResilienceContextPool.Shared.Return(context); // Assess policy result if (pipelineResult.Exception is null) { int result = pipelineResult.Result; // Process result } else { Exception exception = pipelineResult.Exception; // Process failure // If needed you can rethrow the exception pipelineResult.ThrowIfException(); } // Access context ResiliencePropertyKey<string> contextKey = new(\"context_key\"); ResiliencePipeline<int> pipelineWithContext = new ResiliencePipelineBuilder<int>() .AddTimeout(new TimeoutStrategyOptions { Timeout = TimeSpan.FromSeconds(1), OnTimeout = args => { args.Context.Properties.Set(contextKey, \"context_value\"); return default; } }) .Build(); context = ResilienceContextPool.Shared.Get(); pipelineResult = await pipelineWithContext.ExecuteOutcomeAsync( static async (ctx, state) => Outcome.FromResult(await MethodAsync(ctx.CancellationToken)), context, \"state\"); context.Properties.TryGetValue(contextKey, out var ctxValue); ResilienceContextPool.Shared.Return(context); Migrating no-op policies For Policy.NoOp or Policy.NoOpAsync, switch to ResiliencePipeline.Empty. For Policy.NoOp<T> or Policy.NoOpAsync<T>, switch to ResiliencePipeline<T>.Empty. Migrating policy registries In v7, the following registry APIs are exposed: IPolicyRegistry<T> IReadOnlyPolicyRegistry<T> IConcurrentPolicyRegistry<T> PolicyRegistry<T> In v8, these have been replaced by: ResiliencePipelineProvider<TKey>: Allows adding and accessing resilience pipelines. ResiliencePipelineRegistry<TKey>: Read-only access to resilience pipelines. The main updates in the new registry include: It's append-only, which means removal of items is not supported to avoid race conditions. It's thread-safe and supports features like dynamic reloading and resource disposal. It allows dynamic creation and caching of resilience pipelines (previously known as policies in v7) using pre-registered delegates. Type safety is enhanced, eliminating the need for casting between policy types. For more details, refer to the pipeline registry documentation. Registry in v7 // Create a registry var registry = new PolicyRegistry(); // Try get a policy registry.TryGet<IAsyncPolicy>(\"my-key\", out IAsyncPolicy? policy); // Try get a generic policy registry.TryGet<IAsyncPolicy<string>>(\"my-key\", out IAsyncPolicy<string>? genericPolicy); // Add a policy registry.Add(\"my-key\", Policy.Timeout(TimeSpan.FromSeconds(10))); // Update a policy registry.AddOrUpdate( \"my-key\", Policy.Timeout(TimeSpan.FromSeconds(10)), (key, previous) => Policy.Timeout(TimeSpan.FromSeconds(10))); Registry in v8 // Create a registry var registry = new ResiliencePipelineRegistry<string>(); // Try get a pipeline registry.TryGetPipeline(\"my-key\", out ResiliencePipeline? pipeline); // Try get a generic pipeline registry.TryGetPipeline<string>(\"my-key\", out ResiliencePipeline<string>? genericPipeline); // Add a pipeline using a builder, when \"my-key\" pipeline is retrieved it will be dynamically built and cached registry.TryAddBuilder(\"my-key\", (builder, context) => builder.AddTimeout(TimeSpan.FromSeconds(10))); // Get or add pipeline registry.GetOrAddPipeline(\"my-key\", builder => builder.AddTimeout(TimeSpan.FromSeconds(10))); Interoperability between policies and resilience pipelines In certain scenarios, you might not want to migrate your code to the v8 API. Instead, you may prefer to use strategies from v8 and apply them to v7 APIs. Polly provides a set of extension methods to support easy conversion from v8 to v7 APIs, as shown in the example below: Note In v8, you have to add the Polly.RateLimiting package to your application otherwise you won't see the AddRateLimiter extension. // First, create a resilience pipeline. ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddRateLimiter(new FixedWindowRateLimiter(new FixedWindowRateLimiterOptions { Window = TimeSpan.FromSeconds(10), PermitLimit = 100 })) .Build(); // Now, convert it to a v7 policy. Note that it can be converted to both sync and async policies. ISyncPolicy syncPolicy = pipeline.AsSyncPolicy(); IAsyncPolicy asyncPolicy = pipeline.AsAsyncPolicy(); // Finally, use it in a policy wrap. ISyncPolicy wrappedPolicy = Policy.Wrap( syncPolicy, Policy.Handle<SomeExceptionType>().Retry(3));"
  },
  "pipelines/index.html": {
    "href": "pipelines/index.html",
    "title": "Resilience pipelines | Polly",
    "keywords": "Resilience pipelines The ResiliencePipeline allows executing arbitrary user-provided callbacks. It is a combination of one or more resilience strategies. Usage The ResiliencePipeline allow executing various synchronous and asynchronous user-provided callbacks as seen in the examples below: // Creating a new resilience pipeline ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddConcurrencyLimiter(100) .Build(); // Executing an asynchronous void callback await pipeline.ExecuteAsync( async token => await MyMethodAsync(token), cancellationToken); // Executing a synchronous void callback pipeline.Execute(() => MyMethod()); // Executing an asynchronous callback that returns a value await pipeline.ExecuteAsync( async token => await httpClient.GetAsync(endpoint, token), cancellationToken); // Executing an asynchronous callback without allocating a lambda await pipeline.ExecuteAsync( static async (state, token) => await state.httpClient.GetAsync(state.endpoint, token), (httpClient, endpoint), // State provided here cancellationToken); // Executing an asynchronous callback and passing custom data // 1. Retrieve a context from the shared pool ResilienceContext context = ResilienceContextPool.Shared.Get(cancellationToken); // 2. Add custom data to the context context.Properties.Set(new ResiliencePropertyKey<string>(\"my-custom-data\"), \"my-custom-data\"); // 3. Execute the callback await pipeline.ExecuteAsync(static async context => { // Retrieve custom data from the context var customData = context.Properties.GetValue( new ResiliencePropertyKey<string>(\"my-custom-data\"), \"default-value\"); Console.WriteLine(\"Custom Data: {0}\", customData); await MyMethodAsync(context.CancellationToken); }, context); // 4. Optionally, return the context to the shared pool ResilienceContextPool.Shared.Return(context); The above samples demonstrate how to use the resilience pipeline within the same scope. Additionally, consider the following: Separate the resilience pipeline's definition from its usage. Inject pipelines into the code that will consume them. This facilitates various unit-testing scenarios. If your application uses Polly in multiple locations, define all pipelines at startup using ResiliencePipelineRegistry or using the AddResiliencePipeline extension. This is a common approach in .NET Core applications. For example, you could create your own extension method on IServiceCollection to configure pipelines consumed elsewhere in your application. public static void ConfigureMyPipelines(IServiceCollection services) { services.AddResiliencePipeline(\"pipeline-A\", builder => builder.AddConcurrencyLimiter(100)); services.AddResiliencePipeline(\"pipeline-B\", builder => builder.AddRetry(new())); // Later, resolve the pipeline by name using ResiliencePipelineProvider<string> or ResiliencePipelineRegistry<string> var pipelineProvider = services.BuildServiceProvider().GetRequiredService<ResiliencePipelineProvider<string>>(); pipelineProvider.GetPipeline(\"pipeline-A\").Execute(() => { }); } Empty resilience pipeline The empty resilience pipeline is a special construct that lacks any resilience strategies. You can access it through the following ways: ResiliencePipeline.Empty ResiliencePipeline<T>.Empty This is particularly useful in test scenarios where implementing resilience strategies could slow down the test execution or over-complicate test setup. Retrieving execution results with Outcome<T> The ResiliencePipeline class provides the ExecuteOutcomeAsync(...) method, which is designed to never throw exceptions. Instead, it stores either the result or the exception within an Outcome<T> struct. // Acquire a ResilienceContext from the pool ResilienceContext context = ResilienceContextPool.Shared.Get(); // Execute the pipeline and store the result in an Outcome<bool> Outcome<bool> outcome = await pipeline.ExecuteOutcomeAsync( static async (context, state) => { Console.WriteLine(\"State: {0}\", state); try { await MyMethodAsync(context.CancellationToken); // Use static utility methods from Outcome to easily create an Outcome<T> instance return Outcome.FromResult(true); } catch (Exception e) { // Create an Outcome<T> instance that holds the exception return Outcome.FromException<bool>(e); } }, context, \"my-state\"); // Return the acquired ResilienceContext to the pool ResilienceContextPool.Shared.Return(context); // Evaluate the outcome if (outcome.Exception is not null) { Console.WriteLine(\"Execution Failed: {0}\", outcome.Exception.Message); } else { Console.WriteLine(\"Execution Result: {0}\", outcome.Result); } Use ExecuteOutcomeAsync(...) in high-performance scenarios where you wish to avoid re-throwing exceptions. Keep in mind that Polly's resilience strategies also make use of the Outcome struct to prevent unnecessary exception throwing."
  },
  "pipelines/resilience-pipeline-registry.html": {
    "href": "pipelines/resilience-pipeline-registry.html",
    "title": "Resilience pipeline registry | Polly",
    "keywords": "Resilience pipeline registry Note This documentation supports the upcoming Polly v8 release. The ResiliencePipelineRegistry<TKey> is designed to create and cache resilience pipeline instances. The registry also implements the ResiliencePipelineProvider<TKey>, allowing read-only access to pipelines. The registry offers these features: Thread-safe retrieval and dynamic creation for both generic and non-generic resilience pipelines. Dynamic reloading of resilience pipelines when configurations change. Capability to register both generic and non-generic resilience pipeline builders, enabling dynamic pipeline instance creation. Automated resource management, which includes disposing of resources linked to resilience pipelines. Note The generic TKey parameter sets the key type for caching individual resilience pipelines within the registry. Typically, you would use the string-based ResiliencePipelineRegistry<string>. Usage To register pipeline builders, use the TryAddBuilder(...) method. This method accepts a callback argument that configures an instance of ResiliencePipelineBuilder for the pipeline being defined. The registry supports both generic and non-generic resilience pipelines. Here's an example demonstrating these features: var registry = new ResiliencePipelineRegistry<string>(); // Register builder for pipeline \"A\" registry.TryAddBuilder(\"A\", (builder, context) => { // Define your pipeline builder.AddRetry(new RetryStrategyOptions()); }); // Register generic builder for pipeline \"A\"; you can use the same key // because generic and non-generic pipelines are stored separately registry.TryAddBuilder<HttpResponseMessage>(\"A\", (builder, context) => { // Define your pipeline builder.AddRetry(new RetryStrategyOptions<HttpResponseMessage>()); }); // Fetch pipeline \"A\" ResiliencePipeline pipelineA = registry.GetPipeline(\"A\"); // Fetch generic pipeline \"A\" ResiliencePipeline<HttpResponseMessage> genericPipelineA = registry.GetPipeline<HttpResponseMessage>(\"A\"); // Returns false since pipeline \"unknown\" isn't registered registry.TryGetPipeline(\"unknown\", out var pipeline); // Throws KeyNotFoundException because pipeline \"unknown\" isn't registered try { registry.GetPipeline(\"unknown\"); } catch (KeyNotFoundException) { // Handle the exception } Additionally, the registry allows you to add pipelines with the GetOrAddPipeline(...) method. In this method, there's no need to register builders. Instead, the caller provides a factory method called when the pipeline isn't cached: var registry = new ResiliencePipelineRegistry<string>(); // Dynamically retrieve or create pipeline \"A\" ResiliencePipeline pipeline = registry.GetOrAddPipeline(\"A\", (builder, context) => { // Define your pipeline builder.AddRetry(new RetryStrategyOptions()); }); // Dynamically retrieve or create generic pipeline \"A\" ResiliencePipeline<HttpResponseMessage> genericPipeline = registry.GetOrAddPipeline<HttpResponseMessage>(\"A\", (builder, context) => { // Define your pipeline builder.AddRetry(new RetryStrategyOptions<HttpResponseMessage>()); }); Registry options The constructor for ResiliencePipelineRegistry<TKey> accepts a parameter of type ResiliencePipelineRegistryOptions<TKey>. This parameter lets you configure the behavior of the registry. Here's a breakdown of the available properties: Property Default Value Description BuilderFactory Function returning a new ResiliencePipelineBuilder each time. Allows consumers to customize builder creation. PipelineComparer EqualityComparer<TKey>.Default Comparer the registry uses to fetch resilience pipelines. BuilderComparer EqualityComparer<TKey>.Default Comparer the registry uses to fetch registered pipeline builders. InstanceNameFormatter null Delegate formatting TKey to instance name. BuilderNameFormatter Function returning the key.ToString() value. Delegate formatting TKey to builder name. [>NOTE] The BuilderName and InstanceName are used in telemetry. Usage example: var options = new ResiliencePipelineRegistryOptions<string> { BuilderComparer = StringComparer.OrdinalIgnoreCase, PipelineComparer = StringComparer.OrdinalIgnoreCase, BuilderFactory = () => new ResiliencePipelineBuilder { InstanceName = \"lets change the defaults\", Name = \"lets change the defaults\", }, BuilderNameFormatter = key => $\"key:{key}\", InstanceNameFormatter = key => $\"instance-key:{key}\", }; var registry = new ResiliencePipelineRegistry<string>(); Even though the example might seem unnecessary, given that the defaults for a registry using the string type are suitable, it showcases the various properties of the registry and how to set them up. This is particularly helpful when you use complex registry keys. Dynamic reloads Dynamic reloading lets you refresh cached pipelines when the reload token, represented as a CancellationToken, is triggered. To enable dynamic reloads: var registry = new ResiliencePipelineRegistry<string>(); registry.TryAddBuilder(\"A\", (builder, context) => { // Add the reload token. Tokens that are already canceled are ignored. context.AddReloadToken(cancellationToken); // Define the pipeline. builder.AddRetry(new RetryStrategyOptions()); }); // This instance remains valid even after a reload. ResiliencePipeline pipeline = registry.GetPipeline(\"A\"); If an error occurs during reloading, the cached pipeline remains, and dynamic reloading stops. You should not reuse the cancellation token when the pipeline is reloaded. Pipelines enabled for reloads remain valid and current post-reload. The registry manages this transparently. How dynamic reloads work Dynamic reloading is a concept anchored in the registry, while the <xref:Polly.ResiliencePipelineBuilder> remains agnostic to it. The registry employs callbacks to configure the builders, and these callbacks are invoked right before the creation of the pipeline. When dynamic reloading is activated, the registry monitors any changes that could affect the pipeline, seamlessly reloading it as needed. The reloading process involves invoking the callback that configures the pipeline; within this callback is also the call to the AddReloadToken method. Thus, each reload also enables dynamic reloads for that particular pipeline. As a consumer, you may opt to stop reloading by simply not invoking the AddReloadToken method. It's crucial to note that if any error occurs during reloading, the previous pipeline is retained, reloading is halted, and Polly emits a ReloadFailed telemetry event. Resource disposal The registry caches and manages all pipelines and resources linked to them. When you dispose of the registry, all pipelines created by it are also disposed of and can't be used anymore. The following example illustrates this: var registry = new ResiliencePipelineRegistry<string>(); // This instance is valid even after reload. ResiliencePipeline pipeline = registry .GetOrAddPipeline(\"A\", (builder, context) => builder.AddTimeout(TimeSpan.FromSeconds(10))); // Dispose the registry registry.Dispose(); try { pipeline.Execute(() => { }); } catch (ObjectDisposedException) { // Using a pipeline that was disposed by the registry } The registry also allows for the registration of dispose callbacks. These are called when a pipeline is discarded, either because of the registry's disposal or after the pipeline has reloaded. The example below works well with dynamic reloads, letting you dispose of the CancellationTokenSource when it's not needed anymore. var registry = new ResiliencePipelineRegistry<string>(); registry.TryAddBuilder(\"A\", (builder, context) => { var cancellation = new CancellationTokenSource(); // Register the source for potential external triggering RegisterCancellationSource(cancellation); // Add the reload token; note that an already cancelled token is disregarded context.AddReloadToken(cancellation.Token); // Configure your pipeline builder.AddRetry(new RetryStrategyOptions()); context.OnPipelineDisposed(() => cancellation.Dispose()); }); Both AddReloadToken(...) and OnPipelineDisposed(...) are used to implement the EnableReloads<TOptions>(...) extension method that is used by the Dependency Injection layer. How resource disposal works Resource disposal occurs when the registry is disposed of or when the pipeline undergoes changes due to dynamic reloads. Upon disposal, all callbacks registered through the OnPipelineDisposed method are invoked. However, actual resource disposal is deferred until the pipeline completes all outgoing executions. It's vital to note that dispose callbacks are associated only with a specific instance of the pipeline. Complex registry keys Though the pipeline registry supports complex keys, we suggest you use them when defining pipelines with the Dependency Injection (DI) containers. For further information, see the section on complex pipeline keys."
  },
  "strategies/circuit-breaker.html": {
    "href": "strategies/circuit-breaker.html",
    "title": "Circuit breaker resilience strategy | Polly",
    "keywords": "Circuit breaker resilience strategy About Options: CircuitBreakerStrategyOptions CircuitBreakerStrategyOptions<T> Extensions: AddCircuitBreaker Strategy Type: Reactive Exceptions: BrokenCircuitException: Thrown when a circuit is broken and the action could not be executed. IsolatedCircuitException: Thrown when a circuit is isolated (held open) by manual override. Note Be aware that the Circuit Breaker strategy rethrows all exceptions, including those that are handled. A Circuit Breaker's role is to monitor faults and break the circuit when a certain threshold is reached; it does not manage retries. Combine the Circuit Breaker with a Retry strategy if needed. Usage // Add circuit breaker with default options. // See https://www.pollydocs.org/strategies/circuit-breaker#defaults for defaults. new ResiliencePipelineBuilder().AddCircuitBreaker(new CircuitBreakerStrategyOptions()); // Add circuit breaker with customized options: // // The circuit will break if more than 50% of actions result in handled exceptions, // within any 10-second sampling duration, and at least 8 actions are processed. new ResiliencePipelineBuilder().AddCircuitBreaker(new CircuitBreakerStrategyOptions { FailureRatio = 0.5, SamplingDuration = TimeSpan.FromSeconds(10), MinimumThroughput = 8, BreakDuration = TimeSpan.FromSeconds(30), ShouldHandle = new PredicateBuilder().Handle<SomeExceptionType>() }); // Handle specific failed results for HttpResponseMessage: new ResiliencePipelineBuilder<HttpResponseMessage>() .AddCircuitBreaker(new CircuitBreakerStrategyOptions<HttpResponseMessage> { ShouldHandle = new PredicateBuilder<HttpResponseMessage>() .Handle<SomeExceptionType>() .HandleResult(response => response.StatusCode == HttpStatusCode.InternalServerError) }); // Monitor the circuit state, useful for health reporting: var stateProvider = new CircuitBreakerStateProvider(); new ResiliencePipelineBuilder<HttpResponseMessage>() .AddCircuitBreaker(new() { StateProvider = stateProvider }) .Build(); /* CircuitState.Closed - Normal operation; actions are executed. CircuitState.Open - Circuit is open; actions are blocked. CircuitState.HalfOpen - Recovery state after break duration expires; actions are permitted. CircuitState.Isolated - Circuit is manually held open; actions are blocked. */ // Manually control the Circuit Breaker state: var manualControl = new CircuitBreakerManualControl(); new ResiliencePipelineBuilder() .AddCircuitBreaker(new() { ManualControl = manualControl }) .Build(); // Manually isolate a circuit, e.g., to isolate a downstream service. await manualControl.IsolateAsync(); // Manually close the circuit to allow actions to be executed again. await manualControl.CloseAsync(); Defaults Property Default Value Description ShouldHandle Predicate that handles all exceptions except OperationCanceledException. Specifies which results and exceptions are managed by the circuit breaker strategy. FailureRatio 0.1 The ratio of failures to successes that will cause the circuit to break/open. MinimumThroughput 100 The minimum number of actions that must occur in the circuit within a specific time slice. SamplingDuration 30 seconds The time period over which failure ratios are calculated. BreakDuration 5 seconds The time period for which the circuit will remain broken/open before attempting to reset. OnClosed null Event triggered when the circuit transitions to the Closed state. OnOpened null Event triggered when the circuit transitions to the Opened state. OnHalfOpened null Event triggered when the circuit transitions to the HalfOpened state. ManualControl null Allows for manual control to isolate or close the circuit. StateProvider null Enables the retrieval of the current state of the circuit. Diagrams State diagram stateDiagram-v2 direction LR [*] --> Closed Closed --> Open: Exceeds threshold Open --> HalfOpen: Elapses break duration HalfOpen --> Closed: Passes the probe HalfOpen --> Open: Fails the probe Whenever someone says the circuit breaks that means the Circuit Breaker transitions from the Closed state to the Open state. Simple Let's suppose we have a circuit breaker strategy wit the following configuration: SamplingDuration: 2 seconds; MinimumThroughput: 2; FailureRatio : 0.5. Simple: happy path sequence diagram The circuit will not break because the actual failure ratio (0.33) will be below the threshold (0.5) after the 3rd call. sequenceDiagram autonumber actor C as Caller participant P as Pipeline participant CB as CircuitBreaker participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore Note over CB: Closed state Note over CB, D: Sampling start activate CB CB->>+D: Invokes D->>-CB: Returns result CB->>P: Returns result P->>C: Returns result C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore CB->>+D: Invokes D->>-CB: Returns result CB->>P: Returns result P->>C: Returns result C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore CB->>+D: Invokes D->>-CB: Fails deactivate CB Note over CB, D: Sampling end CB->>P: Propagates failure P->>C: Propagates failure Simple: unhappy path sequence diagram The circuit will break because the actual failure ratio meets the threshold (0.5) after the 2nd call. sequenceDiagram autonumber actor C as Caller participant P as Pipeline participant CB as CircuitBreaker participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore Note over CB: Closed state Note over CB, D: Sampling start activate CB CB->>+D: Invokes D->>-CB: Returns result CB->>P: Returns result P->>C: Returns result C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore CB->>+D: Invokes D->>-CB: Fails Note over CB: Moves to Open state CB->>P: Propagates failure P->>C: Propagates failure C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore CB->>CB: Rejects request CB->>P: Throws <br/>BrokenCircuitException P->>C: Propagates exception deactivate CB Note over CB, D: Sampling end Complex Let's suppose we have a circuit breaker strategy with the following configuration: SamplingDuration: 2 seconds; MinimumThroughput: 2; FailureRatio: 0.5; BreakDuration:1 second. Complex: happy path sequence diagram sequenceDiagram autonumber actor C as Caller participant P as Pipeline participant CB as CircuitBreaker participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore Note over CB: Closed state CB->>+D: Invokes D->>-CB: Fails CB->>P: Propagates failure P->>C: Propagates failure C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore CB->>+D: Invokes D->>-CB: Fails Note over CB: Moves to Open state Note over CB: Break duration start CB->>P: Propagates failure P->>C: Propagates failure C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore CB->>CB: Rejects request CB->>P: Throws <br/>BrokenCircuitException P->>C: Propagates exception C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore Note over CB: Break duration end Note over CB: Moves to HalfOpen state CB->>+D: Invokes D->>-CB: Returns result Note over CB: Moves to Closed state CB->>P: Returns result P->>C: Returns result Complex: unhappy path sequence diagram sequenceDiagram autonumber actor C as Caller participant P as Pipeline participant CB as CircuitBreaker participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore Note over CB: Closed state CB->>+D: Invokes D->>-CB: Fails CB->>P: Propagates failure P->>C: Propagates failure C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore CB->>+D: Invokes D->>-CB: Fails Note over CB: Moves to Open state Note over CB: Break duration start CB->>P: Propagates failure P->>C: Propagates failure C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore CB->>CB: Rejects request CB->>P: Throws <br/>BrokenCircuitException P->>C: Propagates exception C->>P: Calls ExecuteAsync P->>CB: Calls ExecuteCore Note over CB: Break duration end Note over CB: Moves to HalfOpen state CB->>+D: Invokes D->>-CB: Fails Note over CB: Moves to Open state CB->>P: Propagates failure P->>C: Propagates failure Resources Making the Netflix API More Resilient Circuit Breaker by Martin Fowler Circuit Breaker Pattern by Microsoft Original Circuit Breaking Article Anti-patterns Over the years, many developers have used Polly in various ways. Some of these recurring patterns may not be ideal. This section highlights the recommended practices and those to avoid. 1 - Using different sleep duration between retry attempts based on Circuit Breaker state Imagine that we have an inner Circuit Breaker and an outer Retry strategies. We would like to define the retry in a way that the sleep duration calculation is taking into account the Circuit Breaker's state. ❌ DON'T Use a closure to branch based on circuit breaker state: var stateProvider = new CircuitBreakerStateProvider(); var circuitBreaker = new ResiliencePipelineBuilder() .AddCircuitBreaker(new() { ShouldHandle = new PredicateBuilder().Handle<HttpRequestException>(), BreakDuration = TimeSpan.FromSeconds(5), StateProvider = stateProvider }) .Build(); var retry = new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = new PredicateBuilder() .Handle<HttpRequestException>() .Handle<BrokenCircuitException>(), DelayGenerator = args => { TimeSpan? delay = TimeSpan.FromSeconds(1); if (stateProvider.CircuitState == CircuitState.Open) { delay = TimeSpan.FromSeconds(5); } return ValueTask.FromResult(delay); } }) .Build(); Reasoning: By default, each strategy is independent and has no any reference to other strategies. We use the (stateProvider) to access the Circuit Breaker's state. However, this approach is not optimal as the retry strategy's DelayGenerator varies based on state. This solution is delicate because the break duration and the sleep duration aren't linked. If a future code maintainer modifies the circuitBreaker's BreakDuration, they might overlook adjusting the sleep duration. ✅ DO Use Context to pass information between strategies: var circuitBreaker = new ResiliencePipelineBuilder() .AddCircuitBreaker(new() { ShouldHandle = new PredicateBuilder().Handle<HttpRequestException>(), BreakDuration = TimeSpan.FromSeconds(5), OnOpened = static args => { args.Context.Properties.Set(SleepDurationKey, args.BreakDuration); return ValueTask.CompletedTask; }, OnClosed = args => { args.Context.Properties.Set(SleepDurationKey, null); return ValueTask.CompletedTask; } }) .Build(); var retry = new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = new PredicateBuilder() .Handle<HttpRequestException>() .Handle<BrokenCircuitException>(), DelayGenerator = static args => { _ = args.Context.Properties.TryGetValue(SleepDurationKey, out var delay); delay ??= TimeSpan.FromSeconds(1); return ValueTask.FromResult(delay); } }) .Build(); Reasoning: Both strategies are less coupled in this approach since they rely on the context and the sleepDurationKey components. The Circuit Breaker shares the BreakDuration through the context when it breaks. When it transitions back to Closed, the sharing is revoked. The Retry strategy fetches the sleep duration dynamically without knowing any specific knowledge about the Circuit Breaker. If adjustments are needed for the BreakDuration, they can be made in one place. 2 - Using different duration for breaks In the case of Retry you can specify dynamically the sleep duration via the DelayGenerator. In the case of Circuit Breaker the BreakDuration is considered constant (can't be changed between breaks). ❌ DON'T Use Task.Delay inside OnOpened: static IEnumerable<TimeSpan> GetSleepDuration() { for (int i = 1; i < 10; i++) { yield return TimeSpan.FromSeconds(i); } } var sleepDurationProvider = GetSleepDuration().GetEnumerator(); sleepDurationProvider.MoveNext(); var circuitBreaker = new ResiliencePipelineBuilder() .AddCircuitBreaker(new() { ShouldHandle = new PredicateBuilder().Handle<HttpRequestException>(), BreakDuration = TimeSpan.FromSeconds(0.5), OnOpened = async args => { await Task.Delay(sleepDurationProvider.Current); sleepDurationProvider.MoveNext(); } }) .Build(); Reasoning: The minimum break duration value is half a second. This implies that each sleep lasts for sleepDurationProvider.Current plus an additional half a second. One might think that setting the BreakDuration to sleepDurationProvider.Current would address this, but it doesn't. This is because the BreakDuration is established only once and isn't re-assessed during each break. circuitBreaker = new ResiliencePipelineBuilder() .AddCircuitBreaker(new() { ShouldHandle = new PredicateBuilder().Handle<HttpRequestException>(), BreakDuration = sleepDurationProvider.Current, OnOpened = async args => { Console.WriteLine($\"Break: {sleepDurationProvider.Current}\"); sleepDurationProvider.MoveNext(); } }) .Build(); ✅ DO The CircuitBreakerStrategyOptions currently do not support defining break durations dynamically. This may be re-evaluated in the future. For now, refer to the first example for a potential workaround. However, please use it with caution. 3 - Wrapping each endpoint with a circuit breaker Imagine that you have to call N number of services via HttpClients. You want to decorate all downstream calls with the service-aware Circuit Breaker. ❌ DON'T Use a collection of Circuit Breakers and explicitly call ExecuteAsync(): // Defined in a common place var uriToCbMappings = new Dictionary<Uri, ResiliencePipeline> { [new Uri(\"https://downstream1.com\")] = GetCircuitBreaker(), // ... [new Uri(\"https://downstreamN.com\")] = GetCircuitBreaker() }; // Used in the downstream 1 client var downstream1Uri = new Uri(\"https://downstream1.com\"); await uriToCbMappings[downstream1Uri].ExecuteAsync(CallXYZOnDownstream1, CancellationToken.None); Reasoning: Whenever you use an HttpClient, you must have a reference to the uriToCbMappings dictionary. It's your responsibility to decorate each network call with the corresponding circuit breaker. ✅ DO Use named and typed HttpClients: foreach (string uri in uris) { builder.Services .AddHttpClient<IResilientClient, ResilientClient>(uri, client => client.BaseAddress = new Uri(uri)) .AddPolicyHandler(GetCircuitBreaker().AsAsyncPolicy<HttpResponseMessage>()); } ... private const string serviceUrl = \"https://downstream1.com\"; public Downstream1Client( IHttpClientFactory namedClientFactory, ITypedHttpClientFactory<ResilientClient> typedClientFactory) { var namedClient = namedClientFactory.CreateClient(serviceUrl); var namedTypedClient = typedClientFactory.CreateClient(namedClient); ... } Reasoning: The HttpClient integrates with Circuit Breaker during startup. There's no need to call ExecuteAsync() directly. The DelegatingHandler handles it automatically. Note The above sample code used the AsAsyncPolicy<HttpResponseMessage>() method to convert the ResiliencePipeline<HttpResponseMessage> to IAsyncPolicy<HttpResponseMessage>. It is required because the AddPolicyHandler() method anticipates an IAsyncPolicy<HttpResponse> parameter. Please be aware that, later an AddResilienceHandler() will be introduced in the Microsoft.Extensions.Http.Resilience package which is the successor of the Microsoft.Extensions.Http.Polly."
  },
  "strategies/fallback.html": {
    "href": "strategies/fallback.html",
    "title": "Fallback resilience strategy | Polly",
    "keywords": "Fallback resilience strategy About Options: FallbackStrategyOptions<T> Extensions: AddFallback Strategy Type: Reactive Usage // Add a fallback/substitute value if an operation fails. new ResiliencePipelineBuilder<UserAvatar>() .AddFallback(new FallbackStrategyOptions<UserAvatar> { ShouldHandle = new PredicateBuilder<UserAvatar>() .Handle<SomeExceptionType>() .HandleResult(r => r is null), FallbackAction = args => Outcome.FromResultAsValueTask(UserAvatar.Blank) }); // Use a dynamically generated value if an operation fails. new ResiliencePipelineBuilder<UserAvatar>() .AddFallback(new FallbackStrategyOptions<UserAvatar> { ShouldHandle = new PredicateBuilder<UserAvatar>() .Handle<SomeExceptionType>() .HandleResult(r => r is null), FallbackAction = args => { var avatar = UserAvatar.GetRandomAvatar(); return Outcome.FromResultAsValueTask(avatar); } }); // Use a default or dynamically generated value, and execute an additional action if the fallback is triggered. new ResiliencePipelineBuilder<UserAvatar>() .AddFallback(new FallbackStrategyOptions<UserAvatar> { ShouldHandle = new PredicateBuilder<UserAvatar>() .Handle<SomeExceptionType>() .HandleResult(r => r is null), FallbackAction = args => { var avatar = UserAvatar.GetRandomAvatar(); return Outcome.FromResultAsValueTask(UserAvatar.Blank); }, OnFallback = args => { // Add extra logic to be executed when the fallback is triggered, such as logging. return default; // Returns an empty ValueTask } }); Defaults Property Default Value Description ShouldHandle Predicate that handles all exceptions except OperationCanceledException. Predicate that determines what results and exceptions are handled by the fallback strategy. FallbackAction Null, Required Fallback action to be executed. OnFallback null Event that is raised when fallback happens. Diagrams Happy path sequence diagram sequenceDiagram actor C as Caller participant P as Pipeline participant F as Fallback participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>F: Calls ExecuteCore F->>+D: Invokes D->>-F: Returns result F->>P: Returns result P->>C: Returns result Unhappy path sequence diagram sequenceDiagram actor C as Caller participant P as Pipeline participant F as Fallback participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>F: Calls ExecuteCore F->>+D: Invokes D->>-F: Fails F->>F: Falls back to<br/>substitute result F->>P: Returns <br/>substituted result P->>C: Returns <br/>substituted result Patterns Fallback after retries When designing resilient systems, a common pattern is to use a fallback after multiple failed retry attempts. This approach is especially relevant when a fallback strategy can provide a sensible default value. // Define a common predicates re-used by both fallback and retries var predicateBuilder = new PredicateBuilder<HttpResponseMessage>() .Handle<HttpRequestException>() .HandleResult(r => r.StatusCode == HttpStatusCode.InternalServerError); var pipeline = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddFallback(new() { ShouldHandle = predicateBuilder, FallbackAction = args => { // Try to resolve the fallback response HttpResponseMessage fallbackResponse = ResolveFallbackResponse(args.Outcome); return Outcome.FromResultAsValueTask(fallbackResponse); } }) .AddRetry(new() { ShouldHandle = predicateBuilder, MaxRetryAttempts = 3, }) .Build(); // Demonstrative execution that always produces invalid result pipeline.Execute(() => new HttpResponseMessage(HttpStatusCode.InternalServerError)); Here's a breakdown of the behavior when the callback produces either an HttpStatusCode.InternalServerError or an HttpRequestException: The fallback strategy initiates by executing the provided callback, then immediately passes the execution to the retry strategy. The retry strategy starts execution, makes 3 retry attempts and yields the outcome that represents an error. The fallback strategy resumes execution, assesses the outcome generated by the callback, and if necessary, supplies the fallback value. The fallback strategy completes its execution. Note The preceding example also demonstrates how to re-use ResiliencePipelineBuilder<HttpResponseMessage> across multiple strategies. Anti-patterns Over the years, many developers have used Polly in various ways. Some of these recurring patterns may not be ideal. This section highlights the recommended practices and ones to avoid. 1 - Using fallback to replace thrown exception ❌ DON'T Throw custom exceptions from the OnFallback delegate: var fallback = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddFallback(new() { ShouldHandle = new PredicateBuilder<HttpResponseMessage>().Handle<HttpRequestException>(), FallbackAction = args => Outcome.FromResultAsValueTask(new HttpResponseMessage()), OnFallback = args => throw new CustomNetworkException(\"Replace thrown exception\", args.Outcome.Exception!) }) .Build(); Reasoning: Throwing an exception from a user-defined delegate can disrupt the normal control flow. ✅ DO Use ExecuteOutcomeAsync and then evaluate the Exception: var outcome = await WhateverPipeline.ExecuteOutcomeAsync(Action, context, \"state\"); if (outcome.Exception is HttpRequestException requestException) { throw new CustomNetworkException(\"Replace thrown exception\", requestException); } Reasoning: This method lets you execute the strategy or pipeline smoothly, without unexpected interruptions. If you repeatedly find yourself writing this exception \"remapping\" logic, consider marking the method you wish to decorate as private and expose the \"remapping\" logic publicly. public static async ValueTask<HttpResponseMessage> Action() { var context = ResilienceContextPool.Shared.Get(); var outcome = await WhateverPipeline.ExecuteOutcomeAsync<HttpResponseMessage, string>( async (ctx, state) => { var result = await ActionCore(); return Outcome.FromResult(result); }, context, \"state\"); if (outcome.Exception is HttpRequestException requestException) { throw new CustomNetworkException(\"Replace thrown exception\", requestException); } ResilienceContextPool.Shared.Return(context); return outcome.Result!; } private static ValueTask<HttpResponseMessage> ActionCore() { // The core logic return ValueTask.FromResult(new HttpResponseMessage()); } 2 - Using retry for fallback Suppose you have a primary and a secondary endpoint. If the primary fails, you want to call the secondary. ❌ DON'T Use retry for fallback: var fallback = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddRetry(new() { ShouldHandle = new PredicateBuilder<HttpResponseMessage>() .HandleResult(res => res.StatusCode == HttpStatusCode.RequestTimeout), MaxRetryAttempts = 1, OnRetry = async args => { args.Context.Properties.Set(fallbackKey, await CallSecondary(args.Context.CancellationToken)); } }) .Build(); var context = ResilienceContextPool.Shared.Get(); var outcome = await fallback.ExecuteOutcomeAsync<HttpResponseMessage, string>( async (ctx, state) => { var result = await CallPrimary(ctx.CancellationToken); return Outcome.FromResult(result); }, context, \"none\"); var result = outcome.Result is not null ? outcome.Result : context.Properties.GetValue(fallbackKey, default); ResilienceContextPool.Shared.Return(context); return result; Reasoning: A retry strategy by default executes the same operation up to N times, where N equals the initial attempt plus MaxRetryAttempts. In this case, that means 2 times. Here, the fallback is introduced as a side effect rather than a replacement. ✅ DO Use fallback to call the secondary: var fallback = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddFallback(new() { ShouldHandle = new PredicateBuilder<HttpResponseMessage>() .HandleResult(res => res.StatusCode == HttpStatusCode.RequestTimeout), OnFallback = async args => await CallSecondary(args.Context.CancellationToken) }) .Build(); return await fallback.ExecuteAsync(CallPrimary, CancellationToken.None); Reasoning: The target code is executed only once. The fallback value is returned directly, eliminating the need for additional code like Context or ExecuteOutcomeAsync(). 3 - Nesting ExecuteAsync calls Combining multiple strategies can be achieved in various ways. However, deeply nesting ExecuteAsync calls can lead to what's commonly referred to as Execute Hell. Note While this isn't strictly tied to the Fallback mechanism, it's frequently observed when Fallback is the outermost layer. ❌ DON'T Nest ExecuteAsync calls: var result = await fallback.ExecuteAsync(async (CancellationToken outerCT) => { return await timeout.ExecuteAsync(static async (CancellationToken innerCT) => { return await CallExternalSystem(innerCT); }, outerCT); }, CancellationToken.None); return result; Reasoning: This is akin to JavaScript's callback hell or the pyramid of doom. It's easy to mistakenly reference the wrong CancellationToken parameter. ✅ DO Use ResiliencePipelineBuilder to chain strategies: var pipeline = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddPipeline(timeout) .AddPipeline(fallback) .Build(); return await pipeline.ExecuteAsync(CallExternalSystem, CancellationToken.None); Reasoning: In this approach, we leverage the escalation mechanism provided by Polly rather than creating our own through nesting. CancellationToken values are automatically propagated between the strategies for you."
  },
  "strategies/hedging.html": {
    "href": "strategies/hedging.html",
    "title": "Hedging resilience strategy | Polly",
    "keywords": "Hedging resilience strategy About Options: HedgingStrategyOptions<T> Extensions: AddHedging Strategy Type: Reactive The hedging strategy enables the re-execution of a user-defined callback if the previous execution takes too long. This approach gives you the option to either run the original callback again or specify a new callback for subsequent hedged attempts. Implementing a hedging strategy can boost the overall responsiveness of the system. However, it's essential to note that this improvement comes at the cost of increased resource utilization. If low latency is not a critical requirement, you may find the retry strategy is more appropriate. This strategy also supports multiple concurrency modes for added flexibility. Note Please do not start any background work when executing actions using the hedging strategy. This strategy can spawn multiple parallel tasks, and as a result multiple background tasks can be started. Usage // Add hedging with default options. // See https://www.pollydocs.org/strategies/hedging#defaults for defaults. new ResiliencePipelineBuilder<HttpResponseMessage>() .AddHedging(new HedgingStrategyOptions<HttpResponseMessage>()); // Add a customized hedging strategy that retries up to 3 times if the execution // takes longer than 1 second or if it fails due to an exception or returns an HTTP 500 Internal Server Error. new ResiliencePipelineBuilder<HttpResponseMessage>() .AddHedging(new HedgingStrategyOptions<HttpResponseMessage> { ShouldHandle = new PredicateBuilder<HttpResponseMessage>() .Handle<SomeExceptionType>() .HandleResult(response => response.StatusCode == HttpStatusCode.InternalServerError), MaxHedgedAttempts = 3, Delay = TimeSpan.FromSeconds(1), ActionGenerator = args => { Console.WriteLine(\"Preparing to execute hedged action.\"); // Return a delegate function to invoke the original action with the action context. // Optionally, you can also create a completely new action to be executed. return () => args.Callback(args.ActionContext); } }); // Subscribe to hedging events. new ResiliencePipelineBuilder<HttpResponseMessage>() .AddHedging(new HedgingStrategyOptions<HttpResponseMessage> { OnHedging = args => { Console.WriteLine($\"OnHedging: Attempt number {args.AttemptNumber}\"); return default; } }); Defaults Property Default Value Description ShouldHandle Predicate that handles all exceptions except OperationCanceledException. Predicate that determines what results and exceptions are handled by the retry strategy. MaxHedgedAttempts 1 The maximum number of hedged actions to use, in addition to the original action. Delay 2 seconds The maximum waiting time before spawning a new hedged action. ActionGenerator Returns the original callback that was passed to the hedging strategy. Generator that creates hedged actions. DelayGenerator null Used for generating custom delays for hedging. If null then Delay is used. OnHedging null Event that is raised when a hedging is performed. You can use the following special values for Delay or in DelayGenerator: 0 seconds - the hedging strategy immediately creates a total of MaxHedgedAttempts and completes when the fastest acceptable result is available. -1 millisecond - this value indicates that the strategy does not create a new hedged task before the previous one completes. This enables scenarios where having multiple concurrent hedged tasks can cause side effects. Concurrency modes In the sections below, explore the different concurrency modes available in the hedging strategy. The behavior is primarily controlled by the Delay property value. Latency mode When the Delay property is set to a value greater than zero, the hedging strategy operates in latency mode. In this mode, additional executions are triggered when the initial ones take too long to complete. By default, the Delay is set to 2 seconds. The primary execution is initiated. If the initial execution either fails or takes longer than the Delay to complete, a new execution is initiated. If the first two executions fail or exceed the Delay (calculated from the last initiated execution), another execution is triggered. The final result is the result of fastest successful execution. If all executions fail, the final result will be the first failure encountered. Latency: happy path sequence diagram The hedging strategy does not trigger because the response arrives faster than the threshold. sequenceDiagram autonumber actor C as Caller participant P as Pipeline participant H as Hedging participant HUC as HedgedUserCallback C->>P: Calls ExecuteAsync P->>H: Calls ExecuteCore Note over H: Wait start activate H H->>+HUC: Invokes HUC-->>HUC: Processes request HUC->>-H: Returns result deactivate H Note over H: Wait end H->>P: Returns result P->>C: Returns result Latency: unhappy path sequence diagram The hedging strategy triggers because the response arrives slower than the threshold. sequenceDiagram autonumber actor C as Caller participant P as Pipeline participant H as Hedging participant D as HedgedUserCallback C->>P: Calls ExecuteAsync P->>H: Calls ExecuteCore Note over H: Wait start activate H activate D H->>D: Invokes (R1) D-->>D: Processes R1<br/> slowly ... Note over H: Wait end H->>D: Invokes (R2) activate D D-->>D: Processes R2<br/> quickly D->>H: Returns result (R2) deactivate D H->>D: Propagates cancellation (R1) deactivate H deactivate D H->>P: Returns result (R2) P->>C: Returns result (R2) Fallback mode In fallback mode, the Delay value should be less than TimeSpan.Zero. This mode allows only a single execution to proceed at a given time. An execution is initiated, and the strategy waits for its completion. If the initial execution fails, new one is initiated. The final result will be the first successful execution. If all executions fail, the final result will be the first failure encountered. Fallback: happy path sequence diagram The hedging strategy triggers because the first attempt fails. It succeeds because the retry attempts do not exceed the MaxHedgedAttempts. sequenceDiagram autonumber actor C as Caller participant P as Pipeline participant H as Hedging participant HUC as HedgedUserCallback C->>P: Calls ExecuteAsync P->>H: Calls ExecuteCore activate H H->>+HUC: Invokes (R1) HUC-->>HUC: Processes R1 HUC->>-H: Fails (R1) H->>+HUC: Invokes (R2) HUC-->>HUC: Processes R2 HUC->>-H: Returns result (R2) deactivate H H->>P: Returns result (R2) P->>C: Returns result (R2) Fallback: unhappy path sequence diagram The hedging strategy triggers because the first attempt fails. It fails because all retry attempts failed as well. sequenceDiagram autonumber actor C as Caller participant P as Pipeline participant H as Hedging participant HUC as HedgedUserCallback C->>P: Calls ExecuteAsync P->>H: Calls ExecuteCore activate H H->>+HUC: Invokes (R1) HUC-->>HUC: Processes R1 HUC->>-H: Fails (R1) H->>+HUC: Invokes (R2) HUC-->>HUC: Processes R2 HUC->>-H: Fails (R2) deactivate H H->>P: Propagates failure (R1) P->>C: Propagates failure (R1) Parallel mode The hedging strategy operates in parallel mode when the Delay property is set to TimeSpan.Zero. In this mode, all executions are initiated simultaneously, and the strategy waits for the fastest completion. Important Use this mode only when absolutely necessary, as it consumes the most resources, particularly when the hedging strategy uses remote resources such as remote HTTP services. All executions are initiated simultaneously, adhering to the MaxHedgedAttempts limit. The final result will be the fastest successful execution. If all executions fail, the final result will be the first failure encountered. Parallel: happy path sequence diagram The hedging strategy triggers because the Delay is set to zero. It succeeds because one of the requests succeeds. sequenceDiagram actor C as Caller participant P as Pipeline participant H as Hedging participant HUC as HedgedUserCallback C->>P: Calls ExecuteAsync P->>H: Calls ExecuteCore activate H par H->>HUC: Invokes (R1) activate HUC and H->>+HUC: Invokes (R2) end HUC-->>HUC: Processes R1<br/> slowly ... HUC-->>HUC: Processes R2<br/> quickly ... HUC->>-H: Returns result (R2) H->>HUC: Propagates cancellation (R1) deactivate HUC deactivate H H->>P: Returns result (R2) P->>C: Returns result (R2) Parallel: unhappy path sequence diagram The hedging strategy triggers because the Delay is set to zero. It succeeds because one of the requests succeeds. sequenceDiagram actor C as Caller participant P as Pipeline participant H as Hedging participant HUC as HedgedUserCallback C->>P: Calls ExecuteAsync P->>H: Calls ExecuteCore activate H par H->>HUC: Invokes (R1) activate HUC and H->>+HUC: Invokes (R2) end HUC-->>HUC: Processes R1 HUC-->>HUC: Processes R2 HUC->>-H: Fails (R2) HUC->>-H: Fails (R1) deactivate H H->>P: Propagates failure (R2) P->>C: Propagates failure (R2) Dynamic mode In dynamic mode, you have the flexibility to control how the hedging strategy behaves during each execution. This control is achieved through the DelayGenerator property. Note The Delay property is disregarded when DelayGenerator is set. Example scenario: First, initiate the first two executions in parallel mode. Subsequently, switch to fallback mode for additional executions. To configure hedging according to the above scenario, use the following code: new ResiliencePipelineBuilder<HttpResponseMessage>() .AddHedging(new() { MaxHedgedAttempts = 3, DelayGenerator = args => { var delay = args.AttemptNumber switch { 0 => TimeSpan.FromSeconds(1), 1 => TimeSpan.FromSeconds(2), _ => System.Threading.Timeout.InfiniteTimeSpan }; return new ValueTask<TimeSpan>(delay); } }); With this configuration, the hedging strategy: Initiates a maximum of 4 executions. This includes initial action and an additional 3 attempts. Allows the first two executions to proceed in parallel, while the third and fourth executions follow the fallback mode. Dynamic: happy path sequence diagram The hedging strategy triggers and switches between modes due to the usage of DelayGenerator. It succeeds because the last request succeeds. sequenceDiagram actor C as Caller participant P as Pipeline participant H as Hedging participant DG as DelayGenerator participant HUC as HedgedUserCallback C->>P: Calls ExecuteAsync P->>H: Calls ExecuteCore activate H Note over H: Parallel mode par H->>DG: Gets delay DG->>H: 1 second H->>HUC: Invokes (R1) activate HUC and H ->> DG: Gets delay DG ->> H: 2 seconds H->>+HUC: Invokes (R2) end HUC-->>HUC: Processes R1 HUC-->>HUC: Processes R2 HUC->>-H: Fails (R2) HUC->>-H: Fails (R1) Note over H: Fallback mode H->>DG: Gets delay DG->>H: Infinite H->>+HUC: Invokes (R3) HUC-->>HUC: Processes R3 HUC->>-H: Fails (R3) H->>DG: Gets delay DG->>H: Infinite H->>+HUC: Invokes (R4) HUC-->>HUC: Processes R4 HUC->>-H: Returns result (R4) deactivate H H->>P: Returns result (R4) P->>C: Returns result (R4) Dynamic: unhappy path sequence diagram The hedging strategy triggers and switches between modes due to the usage of DelayGenerator. It fails because all requests fail. sequenceDiagram actor C as Caller participant P as Pipeline participant H as Hedging participant DG as DelayGenerator participant HUC as HedgedUserCallback C->>P: Calls ExecuteAsync P->>H: Calls ExecuteCore activate H Note over H: Parallel mode par H->>DG: Gets delay DG->>H: 1 second H->>HUC: Invokes (R1) activate HUC and H->>DG: Gets delay DG->>H: 2 seconds H->>+HUC: Invokes (R2) end HUC-->>HUC: Processes R1 HUC-->>HUC: Processes R2 HUC->>-H: Fails (R2) HUC->>-H: Fails (R1) Note over H: Fallback mode H->>DG: Gets delay DG->>H: Infinite H->>+HUC: Invokes (R3) HUC-->>HUC: Processes R3 HUC->>-H: Fails (R3) H -> DG: Gets delay DG->>H: Infinite H->>+HUC: Invokes (R4) HUC-->>HUC: Processes R4 HUC->>-H: Fails (R4) deactivate H H->>P: Propagates failure (R3) P->>C: Propagates failure (R3) Action generator The hedging options include an ActionGenerator property, allowing you to customize the actions executed during hedging. By default, the ActionGenerator returns the original callback passed to the strategy. The original callback also includes any logic introduced by subsequent resilience strategies. For more advanced scenarios, the ActionGenerator can be used to return entirely new hedged actions, as demonstrated in the example below: new ResiliencePipelineBuilder<HttpResponseMessage>() .AddHedging(new() { ActionGenerator = args => { // You can access data from the original (primary) context here var customData = args.PrimaryContext.Properties.GetValue(customDataKey, \"default-custom-data\"); Console.WriteLine($\"Hedging, Attempt: {args.AttemptNumber}, Custom Data: {customData}\"); // Here, we can access the original callback and return it or return a completely new action var callback = args.Callback; // A function that returns a ValueTask<Outcome<HttpResponseMessage>> is required. return async () => { try { // A dedicated ActionContext is provided for each hedged action. // It comes with a separate CancellationToken created specifically for this hedged attempt, // which can be cancelled later if needed. // // Note that the \"MyRemoteCallAsync\" call won't have any additional resilience applied. // You are responsible for wrapping it with any additional resilience pipeline. var response = await MyRemoteCallAsync(args.ActionContext.CancellationToken); return Outcome.FromResult(response); } catch (Exception e) { // Note: All exceptions should be caught and converted to Outcome. return Outcome.FromException<HttpResponseMessage>(e); } }; } }); Parameterized callbacks and action generator When you have control over the callbacks that the resilience pipeline receives, you can parameterize them. This flexibility allows for reusing the callbacks within an action generator. A common use case is with DelegatingHandler. Here, you can parameterize the HttpRequestMessage: internal class HedgingHandler : DelegatingHandler { private readonly ResiliencePipeline<HttpResponseMessage> _pipeline; public HedgingHandler(ResiliencePipeline<HttpResponseMessage> pipeline) { _pipeline = pipeline; } protected override async Task<HttpResponseMessage> SendAsync(HttpRequestMessage request, CancellationToken cancellationToken) { var context = ResilienceContextPool.Shared.Get(cancellationToken); // Store the incoming request in the context context.Properties.Set(ResilienceKeys.RequestMessage, request); try { return await _pipeline.ExecuteAsync(async cxt => { // Allow the pipeline to use request message that was stored in the context. // This allows replacing the request message with a new one in the resilience pipeline. request = cxt.Properties.GetValue(ResilienceKeys.RequestMessage, request); return await base.SendAsync(request, cxt.CancellationToken); }, context); } finally { ResilienceContextPool.Shared.Return(context); } } } Where ResilienceKeys is defined as: internal static class ResilienceKeys { public static readonly ResiliencePropertyKey<HttpRequestMessage> RequestMessage = new(\"MyFeature.RequestMessage\"); } In your ActionGenerator, you can easily provide your own HttpRequestMessage to ActionContext, and the original callback will use it: new ResiliencePipelineBuilder<HttpResponseMessage>() .AddHedging(new() { ActionGenerator = args => { if (!args.PrimaryContext.Properties.TryGetValue(ResilienceKeys.RequestMessage, out var request)) { throw new InvalidOperationException(\"The request message must be provided.\"); } // Prepare a new request message for the callback, potentially involving: // // - Cloning the request message // - Providing alternate endpoint URLs request = PrepareRequest(request); // Override the request message in the action context args.ActionContext.Properties.Set(ResilienceKeys.RequestMessage, request); // Then, execute the original callback return () => args.Callback(args.ActionContext); } });"
  },
  "strategies/index.html": {
    "href": "strategies/index.html",
    "title": "Resilience strategies | Polly",
    "keywords": "Resilience strategies Resilience strategies are essential components of Polly, designed to execute user-defined callbacks while adding an extra layer of resilience. These strategies can't be executed directly; they must be run through a resilience pipeline. Polly provides an API to construct resilience pipelines by incorporating one or more resilience strategies through the pipeline builders. Polly categorizes resilience strategies into two main groups: Reactive: These strategies handle specific exceptions that are thrown, or results that are returned, by the callbacks executed through the strategy. Proactive: Unlike reactive strategies, proactive strategies do not focus on handling errors by the callbacks might throw or return. They can make proactive decisions to cancel or reject the execution of callbacks (e.g., using a rate limiter or a timeout resilience strategy). Built-in strategies Strategy Reactive Premise AKA How does the strategy mitigate? Retry Yes Many faults are transient and may self-correct after a short delay. Maybe it's just a blip Allows configuring automatic retries. Circuit-breaker Yes When a system is seriously struggling, failing fast is better than making users/callers wait. Protecting a faulting system from overload can help it recover. Stop doing it if it hurts Give that system a break Breaks the circuit (blocks executions) for a period, when faults exceed some pre-configured threshold. Timeout No Beyond a certain wait, a success result is unlikely. Don't wait forever Guarantees the caller won't have to wait beyond the timeout. Rate Limiter No Limiting the rate a system handles requests is another way to control load. This can apply to the way your system accepts incoming calls, and/or to the way you call downstream services. Slow down a bit, will you? Constrains executions to not exceed a certain rate. Fallback Yes Things will still fail - plan what you will do when that happens. Degrade gracefully Defines an alternative value to be returned (or action to be executed) on failure. Hedging Yes Things can be slow sometimes, plan what you will do when that happens. Hedge your bets Executes parallel actions when things are slow and waits for the fastest one. Usage Extensions for adding resilience strategies to the builders are provided by each strategy. Depending on the type of strategy, these extensions may be available for both ResiliencePipelineBuilder and ResiliencePipelineBuilder<T> or just one of them. Proactive strategies like timeout or rate limiter are available for both types of builders, while specialized reactive strategies are only available for ResiliencePipelineBuilder<T>. Adding multiple resilience strategies is supported. Each resilience strategy provides: Extensions for the resilience strategy builders. Configuration options (e.g., RetryStrategyOptions) to specify the strategy's behavior. Here's an simple example: ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddTimeout(new TimeoutStrategyOptions { Timeout = TimeSpan.FromSeconds(5) }) .Build(); Note The configuration options are automatically validated by Polly and come with sensible defaults. Therefore, you don't have to specify all the properties unless needed. Fault handling Each reactive strategy provides access to the ShouldHandle predicate property. This property offers a mechanism to decide whether the resilience strategy should manage the fault or result returned after execution. Setting up the predicate can be accomplished in the following ways: Manually setting the predicate: Directly configure the predicate. The advised approach involves using switch expressions for maximum flexibility, and also allows the incorporation of asynchronous predicates. Employing PredicateBuilder: The PredicateBuilder class provides a more straight-forward method to configure the predicates, akin to predicate setups in earlier Polly versions. The examples below illustrate these: Predicates var options = new RetryStrategyOptions<HttpResponseMessage> { // For greater flexibility, you can directly use the ShouldHandle delegate with switch expressions. ShouldHandle = args => args.Outcome switch { // Strategies may offer rich arguments for result handling. // For instance, the retry strategy exposes the number of attempts made. _ when args.AttemptNumber > 3 => PredicateResult.False(), { Exception: HttpRequestException } => PredicateResult.True(), { Exception: TimeoutRejectedException } => PredicateResult.True(), // You can handle multiple exceptions { Result: HttpResponseMessage response } when !response.IsSuccessStatusCode => PredicateResult.True(), _ => PredicateResult.False() } }; Notes from the preceding example: Switch expressions are used to determine whether to retry on not. PredicateResult.True() is a shorthand for new ValueTask<bool>(true). ShouldHandle predicates are asynchronous and use the type Func<Args<TResult>, ValueTask<bool>>. The Args<TResult> acts as a placeholder, and each strategy defines its own arguments. Multiple exceptions can be handled using switch expressions. Asynchronous predicates You can also use asynchronous delegates for more advanced scenarios, such as retrying based on the response body: var options = new RetryStrategyOptions<HttpResponseMessage> { ShouldHandle = async args => { if (args.Outcome.Exception is not null) { return args.Outcome.Exception switch { HttpRequestException => true, TimeoutRejectedException => true, _ => false }; } // Determine whether to retry asynchronously or not based on the result. return await ShouldRetryAsync(args.Outcome.Result!, args.Context.CancellationToken); } }; Predicate builder <xref:Polly.PredicateBuilder>, or <xref:Polly.PredicateBuilder`1>, is a utility class aimed at simplifying the configuration of predicates: // Use PredicateBuilder<HttpResponseMessage> to simplify the setup of the ShouldHandle predicate. var options = new RetryStrategyOptions<HttpResponseMessage> { ShouldHandle = new PredicateBuilder<HttpResponseMessage>() .HandleResult(response => !response.IsSuccessStatusCode) // Handle results .Handle<HttpRequestException>() // Or handle exception .Handle<TimeoutRejectedException>() // Chaining is supported }; The preceding sample: Uses HandleResult to register a predicate that determines whether the result should be handled or not. Uses Handle to handle multiple exceptions types. Note When using PredicateBuilder instead of manually configuring the predicate, there is a minor performance impact. Each method call on PredicateBuilder registers a new predicate, which must be invoked when evaluating the outcome."
  },
  "strategies/rate-limiter.html": {
    "href": "strategies/rate-limiter.html",
    "title": "Rate limiter resilience strategy | Polly",
    "keywords": "Rate limiter resilience strategy About Options: RateLimiterStrategyOptions Extensions: AddRateLimiter, AddConcurrencyLimiter Strategy Type: Proactive Exceptions: RateLimiterRejectedException: Thrown when a rate limiter rejects an execution. Package: Polly.RateLimiting The rate limiter resilience strategy controls the number of operations that can pass through it. This strategy is a thin layer over the API provided by the System.Threading.RateLimiting package. Further reading: Announcing rate limiting for .NET Rate limiting API documentation Usage // Add rate limiter with default options. // See https://www.pollydocs.org/strategies/rate-limiter#defaults for defaults. new ResiliencePipelineBuilder() .AddRateLimiter(new RateLimiterStrategyOptions()); // Create a rate limiter to allow a maximum of 100 concurrent executions and a queue of 50. new ResiliencePipelineBuilder() .AddConcurrencyLimiter(100, 50); // Create a rate limiter that allows 100 executions per minute. new ResiliencePipelineBuilder() .AddRateLimiter(new SlidingWindowRateLimiter(new SlidingWindowRateLimiterOptions { PermitLimit = 100, Window = TimeSpan.FromMinutes(1) })); Example execution: var pipeline = new ResiliencePipelineBuilder().AddConcurrencyLimiter(100, 50).Build(); try { // Execute an asynchronous text search operation. var result = await pipeline.ExecuteAsync( token => TextSearchAsync(query, token), cancellationToken); } catch (RateLimiterRejectedException ex) { // Handle RateLimiterRejectedException, // that can optionally contain information about when to retry. if (ex.RetryAfter is TimeSpan retryAfter) { Console.WriteLine($\"Retry After: {retryAfter}\"); } } Defaults Property Default Value Description RateLimiter null Generator that creates a RateLimitLease for executions. DefaultRateLimiterOptions PermitLimit set to 1000 and QueueLimit set to 0. The options for the default concurrency limiter that will be used when RateLimiter is null. OnRejected null Event that is raised when the execution is rejected by the rate limiter. Diagrams Rate Limiter Let's suppose we have a rate limiter strategy with PermitLimit : 1 and Window : 10 seconds. Rate Limiter: happy path sequence diagram sequenceDiagram actor C as Caller participant P as Pipeline participant RL as RateLimiter participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>RL: Calls ExecuteCore Note over RL,D: Window start RL->>+D: Invokes D->>-RL: Returns result RL->>P: Returns result P->>C: Returns result Note over C: Several seconds later... Note over RL,D: Window end C->>P: Calls ExecuteAsync P->>RL: Calls ExecuteCore Note over RL,D: Window start RL->>+D: Invokes D->>-RL: Returns result RL->>P: Returns result P->>C: Returns result Note over RL,D: Window end Rate limiter: unhappy path sequence diagram sequenceDiagram actor C as Caller participant P as Pipeline participant RL as RateLimiter participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>RL: Calls ExecuteCore Note over RL,D: Window start RL->>+D: Invokes D->>-RL: Returns result RL->>P: Returns result P->>C: Returns result Note over C: Few seconds later... C->>P: Calls ExecuteAsync P->>RL: Calls ExecuteCore RL->>RL: Rejects request RL->>P: Throws <br/>RateLimiterRejectedException P->>C: Propagates exception Note over RL,D: Window end Concurrency Limiter Let's suppose we have a concurrency limiter strategy with PermitLimit : 1 and QueueLimit : 1. Concurrency limiter: happy path sequence diagram sequenceDiagram actor C1 as Caller1 actor C2 as Caller2 participant P as Pipeline participant CL as ConcurrencyLimiter participant D as DecoratedUserCallback par C1->>P: Calls ExecuteAsync and C2->>P: Calls ExecuteAsync end P->>CL: Calls ExecuteCore CL->>+D: Invokes (C1) P->>CL: Calls ExecuteCore CL->>CL: Queues request D->>-CL: Returns result (C1) CL->>P: Returns result (C1) CL->>+D: Invokes (C2) P->>C1: Returns result D->>-CL: Returns result (C2) CL->>P: Returns result (C2) P->>C2: Returns result Concurrency Limiter: unhappy path sequence diagram sequenceDiagram actor C1 as Caller1 actor C2 as Caller2 actor C3 as Caller3 participant P as Pipeline participant CL as ConcurrencyLimiter participant D as DecoratedUserCallback par C1->>P: Calls ExecuteAsync and C2->>P: Calls ExecuteAsync and C3->>P: Calls ExecuteAsync end P->>CL: Calls ExecuteCore CL->>+D: Invokes (C1) P->>CL: Calls ExecuteCore CL->>CL: Queues request (C2) P->>CL: Calls ExecuteCore CL->>CL: Rejects request (C3) CL->>P: Throws <br/>RateLimiterRejectedException P->>C3: Propagates exception D->>-CL: Returns result (C1) CL->>P: Returns result (C1) CL->>+D: Invokes (C2) P->>C1: Returns result D->>-CL: Returns result (C2) CL->>P: Returns result (C2) P->>C2: Returns result Disposal of rate limiters The RateLimiter is a disposable resource. When you explicitly create a RateLimiter instance, it's good practice to dispose of it once it's no longer needed. This is usually not an issue when manually creating resilience pipelines using the ResiliencePipelineBuilder. However, when dynamic reloads are enabled, failing to dispose of discarded rate limiters can lead to excessive resource consumption. Fortunately, Polly provides a way to dispose of discarded rate limiters, as demonstrated in the example below: services .AddResiliencePipeline(\"my-pipeline\", (builder, context) => { var options = context.GetOptions<ConcurrencyLimiterOptions>(\"my-concurrency-options\"); // This call enables dynamic reloading of the pipeline // when the named ConcurrencyLimiterOptions change. context.EnableReloads<ConcurrencyLimiterOptions>(\"my-concurrency-options\"); var limiter = new ConcurrencyLimiter(options); builder.AddRateLimiter(limiter); // Dispose of the limiter when the pipeline is disposed. context.OnPipelineDisposed(() => limiter.Dispose()); }); The above example uses the AddResiliencePipeline(...) extension method to configure the pipeline. However, a similar approach can be taken when directly using the ResiliencePipelineRegistry<T>. Partitioned rate limiter For advanced use-cases, the partitioned rate limiter is also available. The following example illustrates how to retrieve a partition key from ResilienceContext using the GetPartitionKey method: var partitionedLimiter = PartitionedRateLimiter.Create<ResilienceContext, string>(context => { // Extract the partition key. string partitionKey = GetPartitionKey(context); return RateLimitPartition.GetConcurrencyLimiter( partitionKey, key => new ConcurrencyLimiterOptions { PermitLimit = 100 }); }); new ResiliencePipelineBuilder() .AddRateLimiter(new RateLimiterStrategyOptions { // Provide a custom rate limiter delegate. RateLimiter = args => { return partitionedLimiter.AcquireAsync(args.Context, 1, args.Context.CancellationToken); } });"
  },
  "strategies/retry.html": {
    "href": "strategies/retry.html",
    "title": "Retry resilience strategy | Polly",
    "keywords": "Retry resilience strategy About Options: RetryStrategyOptions RetryStrategyOptions<T> Extensions: AddRetry Strategy Type: Reactive Usage // Add retry using the default options. // See https://www.pollydocs.org/strategies/retry#defaults for defaults. new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions()); // For instant retries with no delay new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { Delay = TimeSpan.Zero }); // For advanced control over the retry behavior, including the number of attempts, // delay between retries, and the types of exceptions to handle. new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { ShouldHandle = new PredicateBuilder().Handle<SomeExceptionType>(), BackoffType = DelayBackoffType.Exponential, UseJitter = true, // Adds a random factor to the delay MaxRetryAttempts = 4, Delay = TimeSpan.FromSeconds(3), }); // To use a custom function to generate the delay for retries new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { MaxRetryAttempts = 2, DelayGenerator = args => { var delay = args.AttemptNumber switch { 0 => TimeSpan.Zero, 1 => TimeSpan.FromSeconds(1), _ => TimeSpan.FromSeconds(5) }; // This example uses a synchronous delay generator, // but the API also supports asynchronous implementations. return new ValueTask<TimeSpan?>(delay); } }); // To extract the delay from the result object new ResiliencePipelineBuilder<HttpResponseMessage>().AddRetry(new RetryStrategyOptions<HttpResponseMessage> { DelayGenerator = args => { if (args.Outcome.Result is HttpResponseMessage responseMessage && TryGetDelay(responseMessage, out TimeSpan delay)) { return new ValueTask<TimeSpan?>(delay); } // Returning null means the retry strategy will use its internal delay for this attempt. return new ValueTask<TimeSpan?>((TimeSpan?)null); } }); // To get notifications when a retry is performed new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { MaxRetryAttempts = 2, OnRetry = args => { Console.WriteLine(\"OnRetry, Attempt: {0}\", args.AttemptNumber); // Event handlers can be asynchronous; here, we return an empty ValueTask. return default; } }); // To keep retrying indefinitely or until success use int.MaxValue. new ResiliencePipelineBuilder().AddRetry(new RetryStrategyOptions { MaxRetryAttempts = int.MaxValue, }); Defaults Property Default Value Description ShouldHandle Predicate that handles all exceptions except OperationCanceledException. Predicate that determines what results and exceptions are handled by the retry strategy. MaxRetryAttempts 3 The maximum number of retries to use, in addition to the original call. Delay 2 seconds The base delay between retries. BackoffType Constant The type of the back-off used to generate the retry delay. UseJitter False Allows adding jitter to retry delays. DelayGenerator null Used for generating custom delays for retries. OnRetry null Action executed when retry occurs. MaxDelay null Caps the calculated retry delay to a specified maximum duration. Diagrams Let's suppose we have a retry strategy with MaxRetryAttempts: 2. Happy path sequence diagram sequenceDiagram actor C as Caller participant P as Pipeline participant R as Retry participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>R: Calls ExecuteCore Note over R,D: Initial attempt R->>+D: Invokes D->>-R: Fails R->>R: Sleeps Note over R,D: 1st retry attempt R->>+D: Invokes D->>-R: Returns result R->>P: Returns result P->>C: Returns result Unhappy path sequence diagram sequenceDiagram actor C as Caller participant P as Pipeline participant R as Retry participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>R: Calls ExecuteCore Note over R,D: Initial attempt R->>+D: Invokes D->>-R: Fails R->>R: Sleeps Note over R,D: 1st retry attempt R->>+D: Invokes D->>-R: Fails R->>R: Sleeps Note over R,D: 2nd retry attempt R->>+D: Invokes D->>-R: Fails R->>P: Propagates failure P->>C: Propagates failure Patterns Limiting the maximum delay In some cases, you might want to set a limit on the calculated delay. This is beneficial when multiple retries are anticipated, and you wish to prevent excessive wait times between these retries. Consider the following example of a long-running background job: ResiliencePipeline pipeline = new ResiliencePipelineBuilder() .AddRetry(new() { Delay = TimeSpan.FromSeconds(2), MaxRetryAttempts = int.MaxValue, BackoffType = DelayBackoffType.Exponential, // Initially, we aim for an exponential backoff, but after a certain number of retries, we set a maximum delay of 15 minutes. MaxDelay = TimeSpan.FromMinutes(15), UseJitter = true }) .Build(); // Background processing while (!cancellationToken.IsCancellationRequested) { await pipeline.ExecuteAsync(async token => { // In the event of a prolonged service outage, we can afford to wait for a successful retry since this is a background task. await SynchronizeDataAsync(token); }, cancellationToken); await Task.Delay(TimeSpan.FromMinutes(30)); // The sync runs every 30 minutes. } Anti-patterns Over the years, many developers have used Polly in various ways. Some of these recurring patterns may not be ideal. This section highlights the recommended practices and those to avoid. 1 - Overusing builder methods ❌ DON'T Overuse Handle/HandleResult: var retry = new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = new PredicateBuilder() .Handle<HttpRequestException>() .Handle<BrokenCircuitException>() .Handle<TimeoutRejectedException>() .Handle<SocketException>() .Handle<RateLimitRejectedException>(), MaxRetryAttempts = 3, }) .Build(); Reasoning: Using multiple Handle/HandleResult methods is redundant. Instead of specifying to retry if the decorated code throws a certain exception repeatedly, it's more efficient to state that retries should occur if any of the retryable exceptions are thrown. ✅ DO Use collections and simple predicate functions: ImmutableArray<Type> networkExceptions = new[] { typeof(SocketException), typeof(HttpRequestException), }.ToImmutableArray(); ImmutableArray<Type> strategyExceptions = new[] { typeof(TimeoutRejectedException), typeof(BrokenCircuitException), typeof(RateLimitRejectedException), }.ToImmutableArray(); ImmutableArray<Type> retryableExceptions = networkExceptions .Union(strategyExceptions) .ToImmutableArray(); var retry = new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = ex => new ValueTask<bool>(retryableExceptions.Contains(ex.GetType())), MaxRetryAttempts = 3, }) .Build(); Reasoning: Grouping exceptions simplifies the configuration and improves reusability. For example, the networkExceptions array can be reused in various strategies such as retry, circuit breaker, and more. 2 - Using retry for periodic execution ❌ DON'T Use a retry strategy to run indefinitely at a specified interval: var retry = new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = _ => ValueTask.FromResult(true), Delay = TimeSpan.FromHours(24), }) .Build(); Reasoning: The waiting period can be either blocking or non-blocking, based on the defined strategy/pipeline. Even when used not used in a blocking manner, it unnecessarily consumes memory that can't be reclaimed by the garbage collector. ✅ DO Use a suitable tool to schedule recurring tasks, such as Quartz.Net, Hangfire, or others. Reasoning: Polly was not designed to support this scenario; its primary purpose is to help manage brief transient failures. Specialized job scheduling tools are more memory-efficient and can be set up to withstand machine failures by using persistent storage. 3 - Combining multiple sleep duration strategies ❌ DON'T Mix increasing values with constant ones: var retry = new ResiliencePipelineBuilder() .AddRetry(new() { DelayGenerator = args => { var delay = args.AttemptNumber switch { <= 5 => TimeSpan.FromSeconds(Math.Pow(2, args.AttemptNumber)), _ => TimeSpan.FromMinutes(3) }; return new ValueTask<TimeSpan?>(delay); } }) .Build(); Reasoning: Using this approach essentially turns the logic into a state machine. Although this offers a concise way to express sleep durations, it has several disadvantages: It doesn't support reusability (for instance, you can't use only the quick retries). The sleep duration logic is closely tied to the AttemptNumber. Testing becomes more challenging. ✅ DO Use two distinct retry strategy options and combine them: var slowRetries = new RetryStrategyOptions { MaxRetryAttempts = 5, Delay = TimeSpan.FromMinutes(3), BackoffType = DelayBackoffType.Constant }; var quickRetries = new RetryStrategyOptions { MaxRetryAttempts = 5, Delay = TimeSpan.FromSeconds(1), UseJitter = true, BackoffType = DelayBackoffType.Exponential }; var retry = new ResiliencePipelineBuilder() .AddRetry(slowRetries) .AddRetry(quickRetries) .Build(); Reasoning: While this method may appear more verbose than the first, it offers greater flexibility. Retry strategies can be arranged in any order (either slower first and then quicker, or the other way around). Different triggers can be defined for the retry strategies, allowing for switches between them based on exceptions or results. The order isn't fixed, so quick and slow retries can alternate. 4 - Branching retry logic based on request URL Suppose you have an HttpClient and you want to add a retry only for specific endpoints. ❌ DON'T Use ResiliencePipeline.Empty and the ?: operator: var retry = IsRetryable(request.RequestUri) ? new ResiliencePipelineBuilder<HttpResponseMessage>().AddRetry(new()).Build() : ResiliencePipeline<HttpResponseMessage>.Empty; Reasoning: The triggering conditions and logic are spread across different sections. This design is not ideal for extensibility since adding more conditions can make the code less readable. ✅ DO Use the ShouldHandle clause to define the triggering logic: var retry = new ResiliencePipelineBuilder<HttpResponseMessage>() .AddRetry(new() { ShouldHandle = _ => ValueTask.FromResult(IsRetryable(request.RequestUri)) }) .Build(); Reasoning: The conditions for triggering are consolidated in a familiar and easily accessible location. You don't need to specify actions for scenarios when the strategy shouldn't be triggered. 5 - Calling a method before/after each retry attempt ❌ DON'T Call a specific method before Execute/ExecuteAsync: var retry = new ResiliencePipelineBuilder() .AddRetry(new() { OnRetry = args => { BeforeEachAttempt(); return ValueTask.CompletedTask; }, }) .Build(); BeforeEachAttempt(); await retry.ExecuteAsync(DoSomething); Reasoning: The OnRetry function is triggered before each retry attempt, but it doesn't activate before the initial attempt since it's not considered a retry. Using this method across various parts can lead to accidentally omitting the BeforeEachAttempt call before every Execute. Even though the naming here is straightforward, in real-world scenarios, your method might not start with 'Before', leading to potential misuse by calling it after the Execute. ✅ DO Group the two method calls: var retry = new ResiliencePipelineBuilder() .AddRetry(new()) .Build(); await retry.ExecuteAsync(ct => { BeforeEachAttempt(); return DoSomething(ct); }); Reasoning: If DoSomething and BeforeEachAttempt are interdependent, group them or declare a simple wrapper to invoke them in the correct sequence. 6 - Having a single strategy for multiple failures Suppose we have an HttpClient that issues a request and then we try to parse a large JSON response. ❌ DON'T Use a single strategy for everything: var builder = new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = new PredicateBuilder().Handle<HttpRequestException>(), MaxRetryAttempts = 3 }); builder.AddTimeout(TimeSpan.FromMinutes(1)); var pipeline = builder.Build(); await pipeline.ExecuteAsync(static async (httpClient, ct) => { var stream = await httpClient.GetStreamAsync(new Uri(\"endpoint\"), ct); var foo = await JsonSerializer.DeserializeAsync<Foo>(stream, cancellationToken: ct); }, httpClient); Reasoning: Previously, it was suggested that you should combine X and Y only if they are part of the same failure domain. In simpler terms, a pipeline should address only one type of failure. ✅ DO Define a strategy for each failure domain: var retry = new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = new PredicateBuilder().Handle<HttpRequestException>(), MaxRetryAttempts = 3 }) .Build(); var stream = await retry.ExecuteAsync( static async (httpClient, ct) => await httpClient.GetStreamAsync(new Uri(\"endpoint\"), ct), httpClient); var timeout = new ResiliencePipelineBuilder<Foo>() .AddTimeout(TimeSpan.FromMinutes(1)) .Build(); var foo = await timeout.ExecuteAsync((ct) => JsonSerializer.DeserializeAsync<Foo>(stream, cancellationToken: ct)); Reasoning: The failure domain of a network call is different from that of deserialization. Using dedicated strategies makes the application more resilient to various transient failures. 7 - Cancelling retry for specific exceptions If you encounter a TimeoutException, you may not want to retry the operation. ❌ DON'T Embed cancellation logic within OnRetry: var ctsKey = new ResiliencePropertyKey<CancellationTokenSource>(\"cts\"); var retry = new ResiliencePipelineBuilder() .AddRetry(new() { OnRetry = args => { if (args.Outcome.Exception is TimeoutException) { if (args.Context.Properties.TryGetValue(ctsKey, out var cts)) { cts.Cancel(); } } return ValueTask.CompletedTask; } }) .Build(); Reasoning: Conditions for triggering retries should be located in ShouldHandle. Bypassing the strategy from within a user-defined delegate—either through an Exception or a CancellationToken—unnecessarily complicates the control flow. ✅ DO Set the condition for retry within ShouldHandle: var retry = new ResiliencePipelineBuilder() .AddRetry(new() { ShouldHandle = args => ValueTask.FromResult(args.Outcome.Exception is not TimeoutException) }) .Build(); Reasoning: As previously mentioned, always use the designated area to define retry conditions. Re-frame your original exit conditions to specify when a retry should be initiated."
  },
  "strategies/timeout.html": {
    "href": "strategies/timeout.html",
    "title": "Timeout resilience strategy | Polly",
    "keywords": "Timeout resilience strategy About Options: TimeoutStrategyOptions Extensions: AddTimeout Strategy Type: Proactive Exceptions: TimeoutRejectedException: Thrown when a delegate executed through a timeout strategy does not complete before the timeout. Usage // Add timeout using the default options. // See https://www.pollydocs.org/strategies/timeout#defaults for defaults. new ResiliencePipelineBuilder() .AddTimeout(new TimeoutStrategyOptions()); // To add a timeout with a custom TimeSpan duration new ResiliencePipelineBuilder() .AddTimeout(TimeSpan.FromSeconds(3)); // To add a timeout using a custom timeout generator function new ResiliencePipelineBuilder() .AddTimeout(new TimeoutStrategyOptions { TimeoutGenerator = args => { // Note: the timeout generator supports asynchronous operations return new ValueTask<TimeSpan>(TimeSpan.FromSeconds(123)); } }); // To add a timeout and listen for timeout events new ResiliencePipelineBuilder() .AddTimeout(new TimeoutStrategyOptions { TimeoutGenerator = args => { // Note: the timeout generator supports asynchronous operations return new ValueTask<TimeSpan>(TimeSpan.FromSeconds(123)); }, OnTimeout = args => { Console.WriteLine($\"{args.Context.OperationKey}: Execution timed out after {args.Timeout.TotalSeconds} seconds.\"); return default; } }); Example execution: var pipeline = new ResiliencePipelineBuilder() .AddTimeout(TimeSpan.FromSeconds(3)) .Build(); HttpResponseMessage httpResponse = await pipeline.ExecuteAsync( async ct => { // Execute a delegate that takes a CancellationToken as an input parameter. return await httpClient.GetAsync(endpoint, ct); }, cancellationToken); Defaults Property Default Value Description Timeout 30 seconds The default timeout used by the strategy. TimeoutGenerator null Generates the timeout for a given execution. OnTimeout null Event that is raised when timeout occurs. Diagrams Happy path sequence diagram sequenceDiagram actor C as Caller participant P as Pipeline participant T as Timeout participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>T: Calls ExecuteCore T->>+D: Invokes D->>D: Performs <br/>long-running <br/>operation D->>-T: Returns result T->>P: Returns result P->>C: Returns result Unhappy path sequence diagram sequenceDiagram actor C as Caller participant P as Pipeline participant T as Timeout participant D as DecoratedUserCallback C->>P: Calls ExecuteAsync P->>T: Calls ExecuteCore T->>+D: Invokes activate T activate D D->>D: Performs <br/>long-running <br/>operation T->T: Times out deactivate T T->>D: Propagates cancellation deactivate D T->>P: Throws <br/>TimeoutRejectedException P->>C: Propagates exception"
  },
  "v7/extensibility.html": {
    "href": "v7/extensibility.html",
    "title": "Custom policies | Polly",
    "keywords": "Custom policies From Polly v7.0 it is possible to create your own custom policies outside Polly. These custom policies can integrate in to all the existing goodness from Polly: the Policy.Handle<>() syntax; PolicyWrap; all the execution-dispatch overloads. For more info see our blog series: Part I: Introducing custom Polly policies and the Polly.Contrib Part II: Authoring a non-reactive custom policy (a policy which acts on all executions) Part III: Authoring a reactive custom policy (a policy which react to faults). Part IV: Custom policies for all execution types: sync and async, generic and non-generic. We provide a starter template for a custom policy for developing your own custom policy."
  }
}